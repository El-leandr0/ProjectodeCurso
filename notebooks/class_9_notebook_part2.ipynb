{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJTpNtMA1KWl"
   },
   "source": [
    "# **Class 9: Part 2 - LangChain Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YduyA2zg1KWm"
   },
   "source": [
    "1. **PromptTemplates**: We will start with PromptTemplates, which are structures that allow more dynamic and reusable prompts for language models. By using placeholders, you will be able to inject custom data into your prompts, making them more adaptable for various applications across different contexts.\n",
    "\n",
    "2. **Output Parsers**: Next, we will discuss Output Parsers, tools that help interpret and process the raw outputs from language models. These parsers can transform responses into structured formats like JSON or extract specific information, making it easier to handle and utilize the output in your applications.\n",
    "\n",
    "3. **Memory**: Memory mechanisms in LangChain will allow models to retain context across interactions. This is crucial for maintaining coherent dialogues, especially when building conversational applications. You will learn how different types of memory can be implemented to store and retrieve past interactions.\n",
    "\n",
    "4. **Chains**: We will explore Chains, which are sequences of calls to language models and other utilities. Chains will enable you to link multiple operations together, allowing more complex interactions and processing workflows while maintaining modularity.\n",
    "\n",
    "5. **Creating a Chatbot**: Finally, we will apply all these concepts to create a simple chatbot. By using prompt templates for questions, output parsers for understanding responses, chains for coordinating the conversation flow, and memory for context retention, you will build a basic yet functional conversational agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21231,
     "status": "ok",
     "timestamp": 1731339727266,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "M0bCItN91Mq5",
    "outputId": "cc1d5053-d2a5-4256-d3ee-5571a564c9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1731339728444,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "VllLx9YK1M_m",
    "outputId": "fbca1773-f506-4eaa-9f1d-b11f3497ebc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Aulas_Projeto_Capstone/today\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/Aulas_Projeto_Capstone/today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38364,
     "status": "ok",
     "timestamp": 1731339766803,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "VJWpGeO61N9v",
    "outputId": "258ec1de-743c-483c-9d1a-279c1d6ce438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.13)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Collecting langchain-experimental\n",
      "  Downloading langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-experimental)\n",
      "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain-experimental)\n",
      "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.0.2)\n",
      "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.6 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-experimental) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-experimental) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-experimental) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-experimental) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.14.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.2.2)\n",
      "Downloading langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: SQLAlchemy, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community, langchain-experimental\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.36\n",
      "    Uninstalling SQLAlchemy-2.0.36:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.36\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.13\n",
      "    Uninstalling langchain-core-0.3.13:\n",
      "      Successfully uninstalled langchain-core-0.3.13\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.4\n",
      "    Uninstalling langchain-0.3.4:\n",
      "      Successfully uninstalled langchain-0.3.4\n",
      "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.7 langchain-community-0.3.5 langchain-core-0.3.15 langchain-experimental-0.3.3 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 typing-inspect-0.9.0\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.15)\n",
      "Collecting openai<2.0.0,>=1.54.0 (from langchain-openai)\n",
      "  Downloading openai-1.54.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (0.1.137)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.66.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Downloading langchain_openai-0.2.6-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.54.3-py3-none-any.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.52.2\n",
      "    Uninstalling openai-1.52.2:\n",
      "      Successfully uninstalled openai-1.52.2\n",
      "Successfully installed langchain-openai-0.2.6 openai-1.54.3 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install python-dotenv\n",
    "!pip install pydantic\n",
    "!pip install langchain\n",
    "!pip install langchain-experimental\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1s9dda61KWo"
   },
   "source": [
    "# LangChain\n",
    "LangChain is an innovative framework designed to streamline the development of applications powered by large language models (LLMs). It offers a set of tools and abstractions that make it easier to build complex, functionality-rich applications by orchestrating interactions with these models. At its core, LangChain provides components such as PromptTemplates, Output Parsers, and Chains, which facilitate the creation of dynamic prompts, structured output processing, and sequences of operations, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1731339875299,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "WFlZ4lmA5ezl"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 679,
     "status": "ok",
     "timestamp": 1731339876197,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "8b1XRvFN5cHO"
   },
   "outputs": [],
   "source": [
    "# Load the API key from the environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"The OPENAI_API_KEY environment variable is not set.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1731339879027,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "WNftg4By1KWp"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_completion(prompt, model='gpt-3.5-turbo', **kwargs):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        **kwargs,# this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "llm = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1dqLvgF1KWq"
   },
   "source": [
    "## Main Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yoIqz6Q1KWq"
   },
   "source": [
    "### PromptTemplates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnHQseek1KWr"
   },
   "source": [
    "#### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q390nCs1KWr"
   },
   "source": [
    "Imagine we want to translate an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1731339936697,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ZSH3fu6g1KWs"
   },
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Exmo(a) Sr(a), \\\n",
    "Espero que este email o(a) encontre bem. \\\n",
    "Venho por este meio solicitar informações detalhadas sobre os serviços que a vossa empresa oferece. \\\n",
    "Estou interessado(a) em saber mais sobre os vossos produtos e soluções, bem como os preços e condições de pagamento. \\\n",
    "Gostaria também de agendar uma reunião para discutir possíveis parcerias e oportunidades de negócio. \\\n",
    "Por favor, indiquem-me a disponibilidade da vossa equipa para um encontro presencial ou virtual. \\\n",
    "Agradeço desde já a vossa atenção e aguardo ansiosamente pela vossa resposta. \\\n",
    "Com os melhores cumprimentos\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1731339954440,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "HNL6ocEc1KWs"
   },
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W14zcNfT1KWt"
   },
   "source": [
    "We prepare a prompt that combines the email and the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1731339968906,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "aKwxv-RI1KWt"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks\n",
    "into a style that is {style}.\n",
    "text: ```{email}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziCPPjjA1KWt"
   },
   "source": [
    "Using the LangChain OpenAI Client returns an object of type AIMessage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2066,
     "status": "ok",
     "timestamp": 1731339980130,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "Gu8YgQqb1KWu",
    "outputId": "2618a94b-aec7-48a6-c883-51a0e959c799"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Dear Sir/Madam,\\n\\nI hope this email finds you well. I am reaching out to request detailed information about the services your company offers. I am interested in learning more about your products and solutions, as well as pricing and payment terms. I would also like to schedule a meeting to discuss potential partnerships and business opportunities. Please let me know the availability of your team for an in-person or virtual meeting. Thank you for your attention and I look forward to your response.\\n\\nBest regards,', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 190, 'total_tokens': 287, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-70c5ae20-9393-474e-b703-bca61d3e6289-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1731339992581,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "gE-Yq8741KWu",
    "outputId": "906565fb-6947-44f7-faa0-d544036b5969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sir/Madam,\n",
      "\n",
      "I hope this email finds you well. I am reaching out to request detailed information about the services your company offers. I am interested in learning more about your products and solutions, as well as pricing and payment terms. I would also like to schedule a meeting to discuss potential partnerships and business opportunities. Please let me know the availability of your team for an in-person or virtual meeting. Thank you for your attention and I look forward to your response.\n",
      "\n",
      "Best regards,\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uv5yXac1KWu"
   },
   "source": [
    "What if we want to repeate the process for another language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8ELvwcG1KWu"
   },
   "source": [
    "#### Solution\n",
    "\n",
    "It is useful to reuse good and complex prompts and detailed.\n",
    "Prompt Templates are a good abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1731340013298,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "Fg6zdDKv1KWu"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1731340040599,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "E8nfGvC21KWv"
   },
   "outputs": [],
   "source": [
    "# Define the system and human message templates\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"Translate the text that is delimited by triple backticks into a style that is {style}.\"\"\"\n",
    ")\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: ```{text}```\"\n",
    ")\n",
    "\n",
    "# Combine them into a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_template,\n",
    "    human_message_template,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1731340050929,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "TbDBVinn1KWv",
    "outputId": "af4b28b0-f29e-4815-f72a-2d84cc5f5529"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1731340059367,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ill0jEV11KWv",
    "outputId": "e2b99e0d-a988-42b0-a7ff-f291e5e0da68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1731340095997,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "bFoyFbyK1KWv"
   },
   "outputs": [],
   "source": [
    "# Define the style and lyrics\n",
    "style = \"\"\"English UK very polite and respectful as if you were royalty, if necessary corrects the grammar\"\"\"\n",
    "\n",
    "lyrics = \"\"\"\n",
    "Liguei pra ouvir a tua voz \\\n",
    "Mas diz se não tiveres a sós \\\n",
    "Eu sei que tenho escutas, tenho meo tenho zon e tenho Vodafone \\\n",
    "Amigos coloridos, tenho vários benefícios nunca friend-zone \\\n",
    "Tipo esse burro do teu ex-damo com bué perfis \\\n",
    "'Tava na escola em frente a um quadro \\\n",
    "Da única vez que ele viu giz \\\n",
    "\"\"\"\n",
    "\n",
    "# Format the message with the given style and lyrics\n",
    "lyrics_message = prompt_template.format_messages(style=style, text=lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1731340107705,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "KJ8eO9PA1KWw",
    "outputId": "cf95dc26-9afd-4642-c5aa-8d6b3f96ae0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the text that is delimited by triple backticks into a style that is English UK very polite and respectful as if you were royalty, if necessary corrects the grammar.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"text: ```\\nLiguei pra ouvir a tua voz Mas diz se não tiveres a sós Eu sei que tenho escutas, tenho meo tenho zon e tenho Vodafone Amigos coloridos, tenho vários benefícios nunca friend-zone Tipo esse burro do teu ex-damo com bué perfis 'Tava na escola em frente a um quadro Da única vez que ele viu giz ```\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1613,
     "status": "ok",
     "timestamp": 1731340111895,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "5NB1QR2G1KWw",
    "outputId": "9e46eeaa-6317-412b-fc20-7c6186eda599"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I humbly beseech thee to lend me thine ear, but only if thou art alone. I am aware that I am being listened to, for I possess Meo, Zon, and Vodafone. I have friends with benefits, never in the friend-zone. Like that fool of thy former lover with numerous profiles. He was at school in front of a blackboard the only time he saw chalk.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 140, 'total_tokens': 225, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-323b853b-5b3f-4f2d-96fa-2dc849eedcdb-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "response = llm.invoke(lyrics_message)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBlpKht-1KWw"
   },
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12IJpB-Z1KWw"
   },
   "source": [
    "#### Motivation\n",
    "Sometimes you want the LLM to output the answer in a given format.\n",
    "Let's start with defining how we would like the LLM output to look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsMAvj411KWy"
   },
   "source": [
    "Example of a product review output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1731340154253,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "N_FP4t2u1KWy",
    "outputId": "8c33742d-7e78-480c-c04d-be725b548efa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2xUM95T1KWy"
   },
   "source": [
    "Example of customer review output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1731340163963,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "7EEyud8Z1KWy"
   },
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZIuiuS-1KWy"
   },
   "source": [
    "Example of prompt to extract the product information from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1731340204342,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "6yQBGzX51KWy"
   },
   "outputs": [],
   "source": [
    "# Define the system and human message templates\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else?\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: {text}\"\n",
    ")\n",
    "\n",
    "# Combine them into a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_template,\n",
    "    human_message_template,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1731340208821,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ATkMHA_q1KWz"
   },
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1731340229491,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "FjklbRf860pp",
    "outputId": "5fb0955b-66ed-408d-8a91-341cd07b3121"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? \\nAnswer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product \\nto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price, \\nand output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\\n\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1731340244359,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ZNVt8Sbh1KWz",
    "outputId": "cd5ae925-1ae7-460c-a420-ae29a4f27179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gift\": true,\n",
      "    \"delivery_days\": 2,\n",
      "    \"price_value\": [\n",
      "        \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1731340253027,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "BKU762RN1KW0",
    "outputId": "9fe2fc8f-e668-441c-fbce-8b486c5aaede"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kr88tg4A1KW0"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1731340266015,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "BBNQ79oX1KW0"
   },
   "outputs": [],
   "source": [
    "# Define the system and human message templates\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else?\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: {text}\"\n",
    ")\n",
    "\n",
    "# Combine them into a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_template,\n",
    "    human_message_template,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3vOSItX1KW0"
   },
   "source": [
    "##### Option 1: StructuredOutputParser and ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1731340274421,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "UqW36TG41KW5"
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.output_parsers import ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1731340296669,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "v4Oq0-5r1KW5"
   },
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema,\n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1731340307330,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "GBQRx0RG1KW5"
   },
   "outputs": [],
   "source": [
    "output_parser1 = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1731340314599,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "sQISCMrI1KW5"
   },
   "outputs": [],
   "source": [
    "format_instructions1 = output_parser1.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731340314950,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "T84gMgA51KW5",
    "outputId": "6bd0f510-7b65-4c8a-f192-117c21a42c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 1317,
     "status": "ok",
     "timestamp": 1731340377852,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "nbPtpj8w1KW6"
   },
   "outputs": [],
   "source": [
    "chain1 = prompt_template | llm | output_parser1\n",
    "output1 = chain1.invoke({\"text\": customer_review, \"format_instructions\": format_instructions1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1731340380672,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "cwkWPi-W1KW6",
    "outputId": "bdc87274-30b4-486d-a486-b8b59ac91f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gift': True, 'delivery_days': '2', 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}\n"
     ]
    }
   ],
   "source": [
    "print(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hv21Fp4-1KW6"
   },
   "source": [
    "##### Option 2: PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1731340454016,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "GA27l_xV1KW6"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class ProductReview(BaseModel):\n",
    "    gift: bool = Field(\n",
    "        description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\"\n",
    "    )\n",
    "    delivery_days: int = Field(\n",
    "        description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\"\n",
    "    )\n",
    "    price_value: List[str] = Field(\n",
    "        description=\"Extract any sentences about the value or price, and output them as a comma-separated Python list.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1731340456180,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "4NvGFq4i1KW6"
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser2 = PydanticOutputParser(pydantic_object=ProductReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1731340459925,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ridMpiTc1KW6"
   },
   "outputs": [],
   "source": [
    "format_instructions2 = output_parser2.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 1786,
     "status": "ok",
     "timestamp": 1731340473170,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "Yj6RwZI11KW6"
   },
   "outputs": [],
   "source": [
    "chain2 = prompt_template | llm | output_parser2\n",
    "output2 = chain2.invoke({\"text\": customer_review, \"format_instructions\": format_instructions2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1731340473170,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "wqUtaASi1KW7",
    "outputId": "205abf15-a308-4859-bbac-6d30855bc4bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductReview(gift=True, delivery_days=2, price_value=[\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1731340511001,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "s_PNEQcJ1KW7",
    "outputId": "efc9b62e-fb88-46b8-b677-97a1419a4eeb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.runnables.base.RunnableSequence</b><br/>def __init__(*steps: RunnableLike, name: Optional[str]=None, first: Optional[Runnable[Any, Any]]=None, middle: Optional[list[Runnable[Any, Any]]]=None, last: Optional[Runnable[Any, Any]]=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py</a>Sequence of Runnables, where the output of each is the input of the next.\n",
       "\n",
       "**RunnableSequence** is the most important composition operator in LangChain\n",
       "as it is used in virtually every chain.\n",
       "\n",
       "A RunnableSequence can be instantiated directly or more commonly by using the `|`\n",
       "operator where either the left or right operands (or both) must be a Runnable.\n",
       "\n",
       "Any RunnableSequence automatically supports sync, async, batch.\n",
       "\n",
       "The default implementations of `batch` and `abatch` utilize threadpools and\n",
       "asyncio gather and will be faster than naive invocation of invoke or ainvoke\n",
       "for IO bound Runnables.\n",
       "\n",
       "Batching is implemented by invoking the batch method on each component of the\n",
       "RunnableSequence in order.\n",
       "\n",
       "A RunnableSequence preserves the streaming properties of its components, so if all\n",
       "components of the sequence implement a `transform` method -- which\n",
       "is the method that implements the logic to map a streaming input to a streaming\n",
       "output -- then the sequence will be able to stream input to output!\n",
       "\n",
       "If any component of the sequence does not implement transform then the\n",
       "streaming will only begin after this component is run. If there are\n",
       "multiple blocking components, streaming begins after the last one.\n",
       "\n",
       "Please note: RunnableLambdas do not support `transform` by default! So if\n",
       "    you need to use a RunnableLambdas be careful about where you place them in a\n",
       "    RunnableSequence (if you need to use the .stream()/.astream() methods).\n",
       "\n",
       "    If you need arbitrary logic and need streaming, you can subclass\n",
       "    Runnable, and implement `transform` for whatever logic you need.\n",
       "\n",
       "Here is a simple example that uses simple functions to illustrate the use of\n",
       "RunnableSequence:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain_core.runnables import RunnableLambda\n",
       "\n",
       "        def add_one(x: int) -&gt; int:\n",
       "            return x + 1\n",
       "\n",
       "        def mul_two(x: int) -&gt; int:\n",
       "            return x * 2\n",
       "\n",
       "        runnable_1 = RunnableLambda(add_one)\n",
       "        runnable_2 = RunnableLambda(mul_two)\n",
       "        sequence = runnable_1 | runnable_2\n",
       "        # Or equivalently:\n",
       "        # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
       "        sequence.invoke(1)\n",
       "        await sequence.ainvoke(1)\n",
       "\n",
       "        sequence.batch([1, 2, 3])\n",
       "        await sequence.abatch([1, 2, 3])\n",
       "\n",
       "Here&#x27;s an example that uses streams JSON output generated by an LLM:\n",
       "\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain_core.output_parsers.json import SimpleJsonOutputParser\n",
       "        from langchain_openai import ChatOpenAI\n",
       "\n",
       "        prompt = PromptTemplate.from_template(\n",
       "            &#x27;In JSON format, give me a list of {topic} and their &#x27;\n",
       "            &#x27;corresponding names in French, Spanish and in a &#x27;\n",
       "            &#x27;Cat Language.&#x27;\n",
       "        )\n",
       "\n",
       "        model = ChatOpenAI()\n",
       "        chain = prompt | model | SimpleJsonOutputParser()\n",
       "\n",
       "        async for chunk in chain.astream({&#x27;topic&#x27;: &#x27;colors&#x27;}):\n",
       "            print(&#x27;-&#x27;)  # noqa: T201\n",
       "            print(chunk, sep=&#x27;&#x27;, flush=True)  # noqa: T201</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 2659);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nTMOqt01KW7"
   },
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSgKHGRZ1KW7"
   },
   "source": [
    "#### Motivation\n",
    "When you interact with this LLM they typically don't remember what you say.\n",
    "Which is useful in conversation for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 968,
     "status": "ok",
     "timestamp": 1731340527761,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "rVSIEgYE1KW7",
    "outputId": "5e1d8528-d625-4cb7-c2b1-adc5bb9abcc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Tiago, nice to meet you! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response1 = llm.invoke(\"Hello my name is Tiago.\")\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1731340532341,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "EY4DJ59F1KW8",
    "outputId": "21c9c40d-d7d2-4340-a66b-6b5a9e2773de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I do not have access to personal information such as your name.\n"
     ]
    }
   ],
   "source": [
    "response1 = llm.invoke(\"What is my name?\")\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fcyj5UJR1KW8"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1731340549818,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "LFygJqAI1KW8"
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnSEqOQC1KW8"
   },
   "source": [
    "Let's build a conversation chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1731340598729,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "hi89orQc1KW8",
    "outputId": "e4d7945d-0ad8-4798-e682-58647ad4ccb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-9b333f3452df>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chat = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1731340604004,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "9HNe6Uz51KW8"
   },
   "outputs": [],
   "source": [
    "# Clear the memory\n",
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1731340639367,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "BoX-cog61KW9",
    "outputId": "7f7baa2b-e131-45df-f51a-0a6c5b3def5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-3a73ef55ee88>:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "conversation = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1731340646981,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "_d0vhbTG1KW9"
   },
   "outputs": [],
   "source": [
    "conversation_result = conversation.invoke(\"Hello my name is Tiago.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1731340649823,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "W_gj9Ppd1KW9",
    "outputId": "ed7f8d59-e08d-4f49-b106-109909b2835b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello my name is Tiago.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello Tiago, nice to meet you. How can I assist you today?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_result['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1731340664539,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "IA2BGR0g1KW9"
   },
   "outputs": [],
   "source": [
    "conversation_result = conversation.invoke(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1731340665789,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "UilwKJdA1KW9",
    "outputId": "8da4ac7a-e23e-402b-8d76-dc38a0d01eb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello my name is Tiago.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello Tiago, nice to meet you. How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Tiago.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_result['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1731340670058,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "Ki6zWDt91KW-",
    "outputId": "1917cf68-1850-4b20-ce01-72743255bdce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Your name is Tiago.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_result['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Zob64oc1KW-"
   },
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGv-QER01KW-"
   },
   "source": [
    "#### Motivation\n",
    "When you want to be modular and reuse prompts you already have. It also simplifies the flow of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 4243,
     "status": "ok",
     "timestamp": 1731340694678,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "dC5Hmc-Y1KW-"
   },
   "outputs": [],
   "source": [
    "answer = get_completion(\"\"\"Give me 6 pairs of (product names | reviews) the reviews migth be in different languages,\n",
    "                          but each product shoud only contain one review, each review should contain at least 30 words.\\\n",
    "                          The output should be in json format with two main keys 'products' and 'reviews' \\\n",
    "                           take into account it is suposse to save on a pandas dataframe. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1731340695274,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "n1B8TYL71KW-",
    "outputId": "135e3524-40b9-4148-819c-080e8dafde7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-a412762127c0>:2: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(answer)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(answer)\n",
    "df.rename(columns={'products': 'Product', 'reviews': 'Review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1731340697429,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "cf8P59Tl1KW-",
    "outputId": "2cda8820-60b0-42e7-d879-cce836d22080"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Product\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"iPhone 12 Pro\",\n          \"AirPods Pro\",\n          \"Fitbit Versa 3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Best phone I've ever had! The camera quality is amazing and the battery life lasts all day. The design is sleek and the performance is top-notch.\",\n          \"\\u00a1Los AirPods Pro son incre\\u00edbles! La calidad del sonido es excelente y la cancelaci\\u00f3n de ruido es impresionante. Son muy c\\u00f3modos de usar durante horas.\",\n          \"I love my Fitbit Versa 3! It tracks my steps, heart rate, and sleep patterns accurately. The battery life is impressive and the display is easy to read. Highly recommend it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8f890f07-6363-4993-9447-42d6717d29f8\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone 12 Pro</td>\n",
       "      <td>Best phone I've ever had! The camera quality i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>¡Los AirPods Pro son increíbles! La calidad de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nintendo Switch</td>\n",
       "      <td>La Nintendo Switch es perfecta para jugar en c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dyson V11 Vacuum</td>\n",
       "      <td>The Dyson V11 Vacuum is a game-changer! It's p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instant Pot Duo</td>\n",
       "      <td>¡La Instant Pot Duo es una maravilla! Cocina l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fitbit Versa 3</td>\n",
       "      <td>I love my Fitbit Versa 3! It tracks my steps, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f890f07-6363-4993-9447-42d6717d29f8')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8f890f07-6363-4993-9447-42d6717d29f8 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8f890f07-6363-4993-9447-42d6717d29f8');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-e00a98bb-494e-4038-9d96-f99ef25e74bb\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e00a98bb-494e-4038-9d96-f99ef25e74bb')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-e00a98bb-494e-4038-9d96-f99ef25e74bb button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_f066b8ba-2fc9-47f3-b273-ed9aa9735bb7\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_f066b8ba-2fc9-47f3-b273-ed9aa9735bb7 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "            Product                                             Review\n",
       "0     iPhone 12 Pro  Best phone I've ever had! The camera quality i...\n",
       "1       AirPods Pro  ¡Los AirPods Pro son increíbles! La calidad de...\n",
       "2   Nintendo Switch  La Nintendo Switch es perfecta para jugar en c...\n",
       "3  Dyson V11 Vacuum  The Dyson V11 Vacuum is a game-changer! It's p...\n",
       "4   Instant Pot Duo  ¡La Instant Pot Duo es una maravilla! Cocina l...\n",
       "5    Fitbit Versa 3  I love my Fitbit Versa 3! It tracks my steps, ..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYbT98x81KW_"
   },
   "source": [
    "Imagine you want to answer customer reviews, and those reviews might be in different languages.\n",
    "\n",
    "And from those reviews you want to extract a summary of the review.\n",
    "\n",
    "Finally you want to answer the review in the same language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgs3XmDa1KW_"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31RbRpJX1KW_"
   },
   "source": [
    "#### SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1731340718041,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "JA8phZ7v1KW_"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1731340737938,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "OFO5mTUH1KXA"
   },
   "outputs": [],
   "source": [
    "# Define the language model\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define the prompt template for translation\n",
    "first_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"Translate the following review to English.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{Review}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain for translating the review to English\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"english_Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1731340744878,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "JLweOxEF1KXB"
   },
   "outputs": [],
   "source": [
    "# Define the prompt template for summarization\n",
    "second_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"Summarize the following review in 1 sentence.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{english_Review}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain for summarizing the English review\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1731340751240,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "1zJ_8iQ61KXB"
   },
   "outputs": [],
   "source": [
    "# Define the prompt template to identify the language of the review\n",
    "third_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"Identify the language of the following review.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{Review}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain for identifying the language of the review\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1731340766857,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "JBv-cZ8Q1KXB"
   },
   "outputs": [],
   "source": [
    "# Define the prompt template for a follow-up message\n",
    "fourth_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"Write a follow-up response to the following summary in the specified language.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"Summary: {summary}\\n\\nLanguage: {language}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain for generating a follow-up message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"followup_message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1731340819753,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "FhQENiIo1KXB"
   },
   "outputs": [],
   "source": [
    "# Overall chain: input = Review, and output = English_Review, summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"english_Review\", \"summary\", \"followup_message\"],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3617,
     "status": "ok",
     "timestamp": 1731340855882,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "VLkvFwKe1KXB",
    "outputId": "563ff215-ca27-416a-c186-2d4d77f58978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = df.Review[1]\n",
    "result= overall_chain.invoke(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731340863167,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "kBjUgpWA9ODA",
    "outputId": "9b647b69-9bfe-4ec5-b5c5-c38e0087a5b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Review': '¡Los AirPods Pro son increíbles! La calidad del sonido es excelente y la cancelación de ruido es impresionante. Son muy cómodos de usar durante horas.',\n",
       " 'english_Review': 'The AirPods Pro are amazing! The sound quality is excellent and noise cancellation is impressive. They are very comfortable to wear for hours.',\n",
       " 'summary': 'The AirPods Pro provide excellent sound quality, impressive noise cancellation, and comfortable wear for extended periods.',\n",
       " 'followup_message': 'Estoy muy contento de que estés disfrutando de la calidad de sonido, la cancelación de ruido impresionante y la comodidad de los AirPods Pro. ¡Es genial que puedas usarlos durante largos periodos sin problemas! ¡Que sigas disfrutándolos al máximo!'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kk70fQVK1KXC"
   },
   "source": [
    "#### RouterChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXaVvbNr1KXC"
   },
   "source": [
    "Imagine we want to have multiple prompts and we want to choose one based on the output of the previous prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1731340936380,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "zbA6rc4I1KXC"
   },
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{text}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts,\n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{text}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{text}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity.\n",
    "\n",
    "Here is a question:\n",
    "{text}\"\"\"\n",
    "\n",
    "\n",
    "default_template = \"\"\"You are a helpful AI assistant. \\\n",
    "You can answer questions on a wide range of topics. \\\n",
    "If you're not sure about an answer, you can say so.\n",
    "\n",
    "Here is the question:\n",
    "{text}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQCyNa511KXC"
   },
   "source": [
    "Now from those prompts lets create prompt tempates and chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1731340943285,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "93gVtfNP1KXC"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "templates = [physics_template, math_template, history_template, computerscience_template, default_template]\n",
    "names = [\"Physics\", \"Math\", \"History\", \"Computer Science\", \"Default\"]\n",
    "destination_chains = {}\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: {text}\"\n",
    ")\n",
    "\n",
    "for system_template, name in zip(templates, names):\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        human_message_template,\n",
    "    ])\n",
    "\n",
    "    destination_chains[name] = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1731340989058,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "SVlzIvJb1KXD",
    "outputId": "3d945e9f-fe5a-4db3-974b-30747ae4669d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[Physics, Math, History, Computer Science, Default]'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations = list(destination_chains.keys())\n",
    "destinations_str = \"[\"+\", \".join(destinations)+\"]\"\n",
    "destinations_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7N1Qx-GN1KXD"
   },
   "source": [
    "Let's create a Pydantic Class to extract the destination chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1731340999779,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "g-1YGFpS1KXD"
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Given a raw text input to a language model select the destination that best suits the input.\"\"\"\n",
    "    destination: Literal[\"Physics\", \"Math\", \"History\", \"Computer Science\", \"Default\"]\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=RouteQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zcu2Ez2c1KXD"
   },
   "source": [
    "Now we need to create a main chain that will be used in the router chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1731341057306,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "utxqITMc1KXD"
   },
   "outputs": [],
   "source": [
    "# Define the system and human message templates\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "\n",
    "Available prompts: {destinations_str}\n",
    "\n",
    "If any of the prompts are not suitable for the input, output 'Default'.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: {text}\"\n",
    ")\n",
    "\n",
    "# Combine them into a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_template,\n",
    "    human_message_template,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 2796,
     "status": "ok",
     "timestamp": 1731341166214,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "GRLAyZ2h1KXE"
   },
   "outputs": [],
   "source": [
    "text = \"What was the first king of portugal?\"\n",
    "\n",
    "# Define the chain that will be used to route the input text to the correct destination\n",
    "route_chain = prompt_template | llm | output_parser\n",
    "\n",
    "# Extract the Pydantic object from the output of the route chain\n",
    "route_object = route_chain.invoke({\"text\": text, \"destinations_str\":destinations_str, \"format_instructions\": output_parser.get_format_instructions()})\n",
    "\n",
    "# Extract the destination from the Pydantic object\n",
    "destination = route_object.destination\n",
    "\n",
    "# Use the destination to invoke the correct destination chain\n",
    "answer = destination_chains[destination].invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1731341175773,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "7bx5XkyD-Ts8",
    "outputId": "647e39e9-c46d-4800-bb30-fcf315b66479"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'History'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1731341179207,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "yP6ONWCT-ONb",
    "outputId": "2d29354e-a94c-4fa7-f378-f8b31b736128"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The first King of Portugal was King Afonso I, also known as Afonso Henriques. He became the first King of Portugal after leading the country to independence from the Kingdom of León in 1139 and establishing the Kingdom of Portugal. Afonso I ruled from 1139 until his death in 1185, and he is considered a key figure in Portuguese history for his role in founding the nation and consolidating its borders.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7To2pejU1KXE"
   },
   "source": [
    "### Final ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1731341221175,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "YB2aJ_Ii1KXE"
   },
   "outputs": [],
   "source": [
    "# Product Database\n",
    "PRODUCT_DATABASE = {\n",
    "    \"Computers and Laptops\": [\n",
    "        \"TechPro Ultrabook\",\n",
    "        \"BlueWave Gaming Laptop\",\n",
    "        \"PowerLite Convertible\",\n",
    "        \"TechPro Desktop\",\n",
    "        \"BlueWave Chromebook\"\n",
    "    ],\n",
    "    \"Smartphones and Accessories\": [\n",
    "        \"SmartX ProPhone\",\n",
    "        \"MobiTech PowerCase\",\n",
    "        \"SmartX MiniPhone\",\n",
    "        \"MobiTech Wireless Charger\",\n",
    "        \"SmartX EarBuds\"\n",
    "    ],\n",
    "    \"Televisions and Home Theater Systems\": [\n",
    "        \"CineView 4K TV\",\n",
    "        \"SoundMax Home Theater\",\n",
    "        \"CineView 8K TV\",\n",
    "        \"SoundMax Soundbar\",\n",
    "        \"CineView OLED TV\"\n",
    "    ],\n",
    "    \"Gaming Consoles and Accessories\": [\n",
    "        \"GameSphere X\",\n",
    "        \"ProGamer Controller\",\n",
    "        \"GameSphere Y\",\n",
    "        \"ProGamer Racing Wheel\",\n",
    "        \"GameSphere VR Headset\"\n",
    "    ],\n",
    "    \"Audio Equipment\": [\n",
    "        \"AudioPhonic Noise-Canceling Headphones\",\n",
    "        \"WaveSound Bluetooth Speaker\",\n",
    "        \"AudioPhonic True Wireless Earbuds\",\n",
    "        \"WaveSound Soundbar\",\n",
    "        \"AudioPhonic Turntable\"\n",
    "    ],\n",
    "    \"Cameras and Camcorders\": [\n",
    "        \"FotoSnap DSLR Camera\",\n",
    "        \"ActionCam 4K\",\n",
    "        \"FotoSnap Mirrorless Camera\",\n",
    "        \"ZoomMaster Camcorder\",\n",
    "        \"FotoSnap Instant Camera\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def format_product_database():\n",
    "    \"\"\"Format the product database for prompt templates\"\"\"\n",
    "    categories = \"\\n\".join(f\"- {category}\" for category in PRODUCT_DATABASE.keys())\n",
    "    products = \"\\n\".join(\n",
    "        f\"{category}:\\n\" + \"\\n\".join(f\"  - {product}\" for product in products)\n",
    "        for category, products in PRODUCT_DATABASE.items()\n",
    "    )\n",
    "    return categories, products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1731341249565,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "uDIuYAk71KXE"
   },
   "outputs": [],
   "source": [
    "categories, products = format_product_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1731341286182,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "w9ti3EDI-yUw",
    "outputId": "f4855347-1836-4705-fb58-3049fa44eca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computers and Laptops:\n",
      "  - TechPro Ultrabook\n",
      "  - BlueWave Gaming Laptop\n",
      "  - PowerLite Convertible\n",
      "  - TechPro Desktop\n",
      "  - BlueWave Chromebook\n",
      "Smartphones and Accessories:\n",
      "  - SmartX ProPhone\n",
      "  - MobiTech PowerCase\n",
      "  - SmartX MiniPhone\n",
      "  - MobiTech Wireless Charger\n",
      "  - SmartX EarBuds\n",
      "Televisions and Home Theater Systems:\n",
      "  - CineView 4K TV\n",
      "  - SoundMax Home Theater\n",
      "  - CineView 8K TV\n",
      "  - SoundMax Soundbar\n",
      "  - CineView OLED TV\n",
      "Gaming Consoles and Accessories:\n",
      "  - GameSphere X\n",
      "  - ProGamer Controller\n",
      "  - GameSphere Y\n",
      "  - ProGamer Racing Wheel\n",
      "  - GameSphere VR Headset\n",
      "Audio Equipment:\n",
      "  - AudioPhonic Noise-Canceling Headphones\n",
      "  - WaveSound Bluetooth Speaker\n",
      "  - AudioPhonic True Wireless Earbuds\n",
      "  - WaveSound Soundbar\n",
      "  - AudioPhonic Turntable\n",
      "Cameras and Camcorders:\n",
      "  - FotoSnap DSLR Camera\n",
      "  - ActionCam 4K\n",
      "  - FotoSnap Mirrorless Camera\n",
      "  - ZoomMaster Camcorder\n",
      "  - FotoSnap Instant Camera\n"
     ]
    }
   ],
   "source": [
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1731341291374,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ljCqS7Fb1KXF"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1731341349785,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ks0jaYKS1KXF"
   },
   "outputs": [],
   "source": [
    "# Define Pydantic models for structured output\n",
    "class ProductCategory(BaseModel):\n",
    "    category: Optional[str] = Field(None, description=\"The product category\")\n",
    "    products: Optional[List[str]] = Field(None, description=\"List of products mentioned\")\n",
    "\n",
    "class ProductQueryResult(BaseModel):\n",
    "    results: List[ProductCategory]\n",
    "\n",
    "product_parser = PydanticOutputParser(pydantic_object=ProductQueryResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1731341374028,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ZASFHjys_HlT",
    "outputId": "fdc5d8dc-2fd9-44f5-e897-adbfe243f461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"ProductCategory\": {\"properties\": {\"category\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The product category\", \"title\": \"Category\"}, \"products\": {\"anyOf\": [{\"items\": {\"type\": \"string\"}, \"type\": \"array\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"List of products mentioned\", \"title\": \"Products\"}}, \"title\": \"ProductCategory\", \"type\": \"object\"}}, \"properties\": {\"results\": {\"items\": {\"$ref\": \"#/$defs/ProductCategory\"}, \"title\": \"Results\", \"type\": \"array\"}}, \"required\": [\"results\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(product_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1731341475545,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "JDyZ_Fji1KXF"
   },
   "outputs": [],
   "source": [
    "# Product identification prompt templates\n",
    "PRODUCT_SYSTEM_TEMPLATE = \"\"\"\n",
    "You are a product identification system for an electronics store.\n",
    "Your task is to analyze customer service queries and identify mentioned products and categories.\n",
    "\n",
    "Available categories:\n",
    "{categories}\n",
    "\n",
    "Available products:\n",
    "{products}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Ensure your response follows the exact format specified in the instructions.\n",
    "\"\"\"\n",
    "\n",
    "PRODUCT_HUMAN_TEMPLATE = \"\"\"\n",
    "Customer Query: {customer_input}\n",
    "\"\"\"\n",
    "\n",
    "product_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(PRODUCT_SYSTEM_TEMPLATE),\n",
    "    HumanMessagePromptTemplate.from_template(PRODUCT_HUMAN_TEMPLATE)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1731341478280,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "nB_-QkI_1KXF"
   },
   "outputs": [],
   "source": [
    "# Product identification chain\n",
    "product_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    output_parser=product_parser,\n",
    "    prompt=product_prompt,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 1538,
     "status": "ok",
     "timestamp": 1731341500338,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "8CdASgjY1KXF"
   },
   "outputs": [],
   "source": [
    "result = product_chain.invoke({\"customer_input\":\"What kind of laptops and CineView 4K TV do you have?\", \"categories\": categories, \"products\": products, \"format_instructions\": product_parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1731341581964,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ia011eEG1KXF",
    "outputId": "173ef3d5-4803-445a-c7e7-6f1b0587b611"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductQueryResult(results=[ProductCategory(category='Computers and Laptops', products=['TechPro Ultrabook', 'BlueWave Gaming Laptop', 'PowerLite Convertible', 'TechPro Desktop', 'BlueWave Chromebook']), ProductCategory(category='Televisions and Home Theater Systems', products=['CineView 4K TV'])])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1731341613211,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "3md7KyhLADKU"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dictionary from the pickle file\n",
    "with open('products_catalog.pkl', 'rb') as handle:\n",
    "  products_catalog = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1731341634450,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "ixSlHlZu1KXG"
   },
   "outputs": [],
   "source": [
    "def get_product_by_name(name):\n",
    "    return products_catalog.get(name, None)\n",
    "\n",
    "def get_products_by_category(category):\n",
    "    return [product for product in products_catalog.values() if product[\"category\"] == category]\n",
    "\n",
    "def generate_output_string(data_list):\n",
    "    output_string = \"\"\n",
    "\n",
    "    if data_list is None:\n",
    "        return output_string\n",
    "\n",
    "    for data in data_list:\n",
    "        try:\n",
    "            # Check if the data is a instance of ProductCategory\n",
    "            if isinstance(data, ProductCategory):\n",
    "\n",
    "                # Check if the category is specified\n",
    "                if data.category:\n",
    "                    #print(f\"Category: {data.category}\")\n",
    "                    category_products = get_products_by_category(data.category)\n",
    "                    for product in category_products:\n",
    "                        output_string += json.dumps(product, indent=4) + \"\\n\"\n",
    "\n",
    "                # Check if the products are specified\n",
    "                if data.products:\n",
    "                    for product_name in data.products:\n",
    "                        #print(f\"Product: {product_name}\")\n",
    "                        product = get_product_by_name(product_name)\n",
    "                        if product:\n",
    "                            output_string += json.dumps(product, indent=4) + \"\\n\"\n",
    "                        else:\n",
    "                            print(f\"Error: Product '{product_name}' not found\")\n",
    "            else:\n",
    "                print(\"Error: Invalid object format\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1731341636913,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "YO08PQTE1KXG"
   },
   "outputs": [],
   "source": [
    "product_info = generate_output_string(result[\"text\"].results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1731341652043,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "URMVKcAqANg7",
    "outputId": "1adc33a2-1609-4ef6-b189-1846dde44fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"TechPro Ultrabook\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"TechPro\",\n",
      "    \"model_number\": \"TP-UB100\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.5,\n",
      "    \"features\": [\n",
      "        \"13.3-inch display\",\n",
      "        \"8GB RAM\",\n",
      "        \"256GB SSD\",\n",
      "        \"Intel Core i5 processor\"\n",
      "    ],\n",
      "    \"description\": \"A sleek and lightweight ultrabook for everyday use.\",\n",
      "    \"price\": 799.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"BlueWave Gaming Laptop\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"BlueWave\",\n",
      "    \"model_number\": \"BW-GL200\",\n",
      "    \"warranty\": \"2 years\",\n",
      "    \"rating\": 4.7,\n",
      "    \"features\": [\n",
      "        \"15.6-inch display\",\n",
      "        \"16GB RAM\",\n",
      "        \"512GB SSD\",\n",
      "        \"NVIDIA GeForce RTX 3060\"\n",
      "    ],\n",
      "    \"description\": \"A high-performance gaming laptop for an immersive experience.\",\n",
      "    \"price\": 1199.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"PowerLite Convertible\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"PowerLite\",\n",
      "    \"model_number\": \"PL-CV300\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.3,\n",
      "    \"features\": [\n",
      "        \"14-inch touchscreen\",\n",
      "        \"8GB RAM\",\n",
      "        \"256GB SSD\",\n",
      "        \"360-degree hinge\"\n",
      "    ],\n",
      "    \"description\": \"A versatile convertible laptop with a responsive touchscreen.\",\n",
      "    \"price\": 699.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"TechPro Desktop\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"TechPro\",\n",
      "    \"model_number\": \"TP-DT500\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.4,\n",
      "    \"features\": [\n",
      "        \"Intel Core i7 processor\",\n",
      "        \"16GB RAM\",\n",
      "        \"1TB HDD\",\n",
      "        \"NVIDIA GeForce GTX 1660\"\n",
      "    ],\n",
      "    \"description\": \"A powerful desktop computer for work and play.\",\n",
      "    \"price\": 999.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"BlueWave Chromebook\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"BlueWave\",\n",
      "    \"model_number\": \"BW-CB100\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.1,\n",
      "    \"features\": [\n",
      "        \"11.6-inch display\",\n",
      "        \"4GB RAM\",\n",
      "        \"32GB eMMC\",\n",
      "        \"Chrome OS\"\n",
      "    ],\n",
      "    \"description\": \"A compact and affordable Chromebook for everyday tasks.\",\n",
      "    \"price\": 249.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"TechPro Ultrabook\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"TechPro\",\n",
      "    \"model_number\": \"TP-UB100\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.5,\n",
      "    \"features\": [\n",
      "        \"13.3-inch display\",\n",
      "        \"8GB RAM\",\n",
      "        \"256GB SSD\",\n",
      "        \"Intel Core i5 processor\"\n",
      "    ],\n",
      "    \"description\": \"A sleek and lightweight ultrabook for everyday use.\",\n",
      "    \"price\": 799.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"BlueWave Gaming Laptop\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"BlueWave\",\n",
      "    \"model_number\": \"BW-GL200\",\n",
      "    \"warranty\": \"2 years\",\n",
      "    \"rating\": 4.7,\n",
      "    \"features\": [\n",
      "        \"15.6-inch display\",\n",
      "        \"16GB RAM\",\n",
      "        \"512GB SSD\",\n",
      "        \"NVIDIA GeForce RTX 3060\"\n",
      "    ],\n",
      "    \"description\": \"A high-performance gaming laptop for an immersive experience.\",\n",
      "    \"price\": 1199.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"PowerLite Convertible\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"PowerLite\",\n",
      "    \"model_number\": \"PL-CV300\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.3,\n",
      "    \"features\": [\n",
      "        \"14-inch touchscreen\",\n",
      "        \"8GB RAM\",\n",
      "        \"256GB SSD\",\n",
      "        \"360-degree hinge\"\n",
      "    ],\n",
      "    \"description\": \"A versatile convertible laptop with a responsive touchscreen.\",\n",
      "    \"price\": 699.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"TechPro Desktop\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"TechPro\",\n",
      "    \"model_number\": \"TP-DT500\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.4,\n",
      "    \"features\": [\n",
      "        \"Intel Core i7 processor\",\n",
      "        \"16GB RAM\",\n",
      "        \"1TB HDD\",\n",
      "        \"NVIDIA GeForce GTX 1660\"\n",
      "    ],\n",
      "    \"description\": \"A powerful desktop computer for work and play.\",\n",
      "    \"price\": 999.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"BlueWave Chromebook\",\n",
      "    \"category\": \"Computers and Laptops\",\n",
      "    \"brand\": \"BlueWave\",\n",
      "    \"model_number\": \"BW-CB100\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.1,\n",
      "    \"features\": [\n",
      "        \"11.6-inch display\",\n",
      "        \"4GB RAM\",\n",
      "        \"32GB eMMC\",\n",
      "        \"Chrome OS\"\n",
      "    ],\n",
      "    \"description\": \"A compact and affordable Chromebook for everyday tasks.\",\n",
      "    \"price\": 249.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"CineView 4K TV\",\n",
      "    \"category\": \"Televisions and Home Theater Systems\",\n",
      "    \"brand\": \"CineView\",\n",
      "    \"model_number\": \"CV-4K55\",\n",
      "    \"warranty\": \"2 years\",\n",
      "    \"rating\": 4.8,\n",
      "    \"features\": [\n",
      "        \"55-inch display\",\n",
      "        \"4K resolution\",\n",
      "        \"HDR\",\n",
      "        \"Smart TV\"\n",
      "    ],\n",
      "    \"description\": \"A stunning 4K TV with vibrant colors and smart features.\",\n",
      "    \"price\": 599.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"SoundMax Home Theater\",\n",
      "    \"category\": \"Televisions and Home Theater Systems\",\n",
      "    \"brand\": \"SoundMax\",\n",
      "    \"model_number\": \"SM-HT100\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.4,\n",
      "    \"features\": [\n",
      "        \"5.1 channel\",\n",
      "        \"1000W output\",\n",
      "        \"Wireless subwoofer\",\n",
      "        \"Bluetooth\"\n",
      "    ],\n",
      "    \"description\": \"A powerful home theater system for an immersive audio experience.\",\n",
      "    \"price\": 399.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"CineView 8K TV\",\n",
      "    \"category\": \"Televisions and Home Theater Systems\",\n",
      "    \"brand\": \"CineView\",\n",
      "    \"model_number\": \"CV-8K65\",\n",
      "    \"warranty\": \"2 years\",\n",
      "    \"rating\": 4.9,\n",
      "    \"features\": [\n",
      "        \"65-inch display\",\n",
      "        \"8K resolution\",\n",
      "        \"HDR\",\n",
      "        \"Smart TV\"\n",
      "    ],\n",
      "    \"description\": \"Experience the future of television with this stunning 8K TV.\",\n",
      "    \"price\": 2999.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"SoundMax Soundbar\",\n",
      "    \"category\": \"Televisions and Home Theater Systems\",\n",
      "    \"brand\": \"SoundMax\",\n",
      "    \"model_number\": \"SM-SB50\",\n",
      "    \"warranty\": \"1 year\",\n",
      "    \"rating\": 4.3,\n",
      "    \"features\": [\n",
      "        \"2.1 channel\",\n",
      "        \"300W output\",\n",
      "        \"Wireless subwoofer\",\n",
      "        \"Bluetooth\"\n",
      "    ],\n",
      "    \"description\": \"Upgrade your TV's audio with this sleek and powerful soundbar.\",\n",
      "    \"price\": 199.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"CineView OLED TV\",\n",
      "    \"category\": \"Televisions and Home Theater Systems\",\n",
      "    \"brand\": \"CineView\",\n",
      "    \"model_number\": \"CV-OLED55\",\n",
      "    \"warranty\": \"2 years\",\n",
      "    \"rating\": 4.7,\n",
      "    \"features\": [\n",
      "        \"55-inch display\",\n",
      "        \"4K resolution\",\n",
      "        \"HDR\",\n",
      "        \"Smart TV\"\n",
      "    ],\n",
      "    \"description\": \"Experience true blacks and vibrant colors with this OLED TV.\",\n",
      "    \"price\": 1499.99\n",
      "}\n",
      "{\n",
      "    \"name\": \"CineView 4K TV\",\n",
      "    \"category\": \"Televisions and Home Theater Systems\",\n",
      "    \"brand\": \"CineView\",\n",
      "    \"model_number\": \"CV-4K55\",\n",
      "    \"warranty\": \"2 years\",\n",
      "    \"rating\": 4.8,\n",
      "    \"features\": [\n",
      "        \"55-inch display\",\n",
      "        \"4K resolution\",\n",
      "        \"HDR\",\n",
      "        \"Smart TV\"\n",
      "    ],\n",
      "    \"description\": \"A stunning 4K TV with vibrant colors and smart features.\",\n",
      "    \"price\": 599.99\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(product_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1731341717687,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "QmUUZYWJ1KXG"
   },
   "outputs": [],
   "source": [
    "# Customer service prompt templates\n",
    "SERVICE_SYSTEM_TEMPLATE = \"\"\"\n",
    "You are a friendly and helpful customer service assistant for a large electronics store.\n",
    "Follow these guidelines:\n",
    "1. Provide concise, helpful responses\n",
    "2. Ask relevant follow-up questions when needed\n",
    "3. Show understanding of specific products mentioned\n",
    "4. Be professional but conversational in tone\n",
    "5. Focus on solving the customer's immediate needs\n",
    "\"\"\"\n",
    "\n",
    "SERVICE_HUMAN_TEMPLATE = \"\"\"\n",
    "Product Information from Query:\n",
    "{product_info}\n",
    "\n",
    "Customer Query: {customer_input}\n",
    "\"\"\"\n",
    "\n",
    "service_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(SERVICE_SYSTEM_TEMPLATE),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    HumanMessagePromptTemplate.from_template(SERVICE_HUMAN_TEMPLATE)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1731341727803,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "QyQab-s91KXG"
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        input_key=\"customer_input\",\n",
    "        return_messages=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1731341733729,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "Z7GJ6cOA1KXH"
   },
   "outputs": [],
   "source": [
    "# Product identification chain\n",
    "service_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=service_prompt,\n",
    "    output_key=\"response\",\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7853,
     "status": "ok",
     "timestamp": 1731341745545,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "G70bxxMe1KXH",
    "outputId": "0fa5e186-a359-45f7-d211-b4614c83c9a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer_input': 'What kind of laptops and CineView 4K TV do you have?',\n",
       " 'product_info': '{\\n    \"name\": \"TechPro Ultrabook\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"TechPro\",\\n    \"model_number\": \"TP-UB100\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.5,\\n    \"features\": [\\n        \"13.3-inch display\",\\n        \"8GB RAM\",\\n        \"256GB SSD\",\\n        \"Intel Core i5 processor\"\\n    ],\\n    \"description\": \"A sleek and lightweight ultrabook for everyday use.\",\\n    \"price\": 799.99\\n}\\n{\\n    \"name\": \"BlueWave Gaming Laptop\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"BlueWave\",\\n    \"model_number\": \"BW-GL200\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.7,\\n    \"features\": [\\n        \"15.6-inch display\",\\n        \"16GB RAM\",\\n        \"512GB SSD\",\\n        \"NVIDIA GeForce RTX 3060\"\\n    ],\\n    \"description\": \"A high-performance gaming laptop for an immersive experience.\",\\n    \"price\": 1199.99\\n}\\n{\\n    \"name\": \"PowerLite Convertible\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"PowerLite\",\\n    \"model_number\": \"PL-CV300\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.3,\\n    \"features\": [\\n        \"14-inch touchscreen\",\\n        \"8GB RAM\",\\n        \"256GB SSD\",\\n        \"360-degree hinge\"\\n    ],\\n    \"description\": \"A versatile convertible laptop with a responsive touchscreen.\",\\n    \"price\": 699.99\\n}\\n{\\n    \"name\": \"TechPro Desktop\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"TechPro\",\\n    \"model_number\": \"TP-DT500\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.4,\\n    \"features\": [\\n        \"Intel Core i7 processor\",\\n        \"16GB RAM\",\\n        \"1TB HDD\",\\n        \"NVIDIA GeForce GTX 1660\"\\n    ],\\n    \"description\": \"A powerful desktop computer for work and play.\",\\n    \"price\": 999.99\\n}\\n{\\n    \"name\": \"BlueWave Chromebook\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"BlueWave\",\\n    \"model_number\": \"BW-CB100\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.1,\\n    \"features\": [\\n        \"11.6-inch display\",\\n        \"4GB RAM\",\\n        \"32GB eMMC\",\\n        \"Chrome OS\"\\n    ],\\n    \"description\": \"A compact and affordable Chromebook for everyday tasks.\",\\n    \"price\": 249.99\\n}\\n{\\n    \"name\": \"TechPro Ultrabook\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"TechPro\",\\n    \"model_number\": \"TP-UB100\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.5,\\n    \"features\": [\\n        \"13.3-inch display\",\\n        \"8GB RAM\",\\n        \"256GB SSD\",\\n        \"Intel Core i5 processor\"\\n    ],\\n    \"description\": \"A sleek and lightweight ultrabook for everyday use.\",\\n    \"price\": 799.99\\n}\\n{\\n    \"name\": \"BlueWave Gaming Laptop\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"BlueWave\",\\n    \"model_number\": \"BW-GL200\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.7,\\n    \"features\": [\\n        \"15.6-inch display\",\\n        \"16GB RAM\",\\n        \"512GB SSD\",\\n        \"NVIDIA GeForce RTX 3060\"\\n    ],\\n    \"description\": \"A high-performance gaming laptop for an immersive experience.\",\\n    \"price\": 1199.99\\n}\\n{\\n    \"name\": \"PowerLite Convertible\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"PowerLite\",\\n    \"model_number\": \"PL-CV300\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.3,\\n    \"features\": [\\n        \"14-inch touchscreen\",\\n        \"8GB RAM\",\\n        \"256GB SSD\",\\n        \"360-degree hinge\"\\n    ],\\n    \"description\": \"A versatile convertible laptop with a responsive touchscreen.\",\\n    \"price\": 699.99\\n}\\n{\\n    \"name\": \"TechPro Desktop\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"TechPro\",\\n    \"model_number\": \"TP-DT500\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.4,\\n    \"features\": [\\n        \"Intel Core i7 processor\",\\n        \"16GB RAM\",\\n        \"1TB HDD\",\\n        \"NVIDIA GeForce GTX 1660\"\\n    ],\\n    \"description\": \"A powerful desktop computer for work and play.\",\\n    \"price\": 999.99\\n}\\n{\\n    \"name\": \"BlueWave Chromebook\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"BlueWave\",\\n    \"model_number\": \"BW-CB100\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.1,\\n    \"features\": [\\n        \"11.6-inch display\",\\n        \"4GB RAM\",\\n        \"32GB eMMC\",\\n        \"Chrome OS\"\\n    ],\\n    \"description\": \"A compact and affordable Chromebook for everyday tasks.\",\\n    \"price\": 249.99\\n}\\n{\\n    \"name\": \"CineView 4K TV\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"CineView\",\\n    \"model_number\": \"CV-4K55\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.8,\\n    \"features\": [\\n        \"55-inch display\",\\n        \"4K resolution\",\\n        \"HDR\",\\n        \"Smart TV\"\\n    ],\\n    \"description\": \"A stunning 4K TV with vibrant colors and smart features.\",\\n    \"price\": 599.99\\n}\\n{\\n    \"name\": \"SoundMax Home Theater\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"SoundMax\",\\n    \"model_number\": \"SM-HT100\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.4,\\n    \"features\": [\\n        \"5.1 channel\",\\n        \"1000W output\",\\n        \"Wireless subwoofer\",\\n        \"Bluetooth\"\\n    ],\\n    \"description\": \"A powerful home theater system for an immersive audio experience.\",\\n    \"price\": 399.99\\n}\\n{\\n    \"name\": \"CineView 8K TV\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"CineView\",\\n    \"model_number\": \"CV-8K65\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.9,\\n    \"features\": [\\n        \"65-inch display\",\\n        \"8K resolution\",\\n        \"HDR\",\\n        \"Smart TV\"\\n    ],\\n    \"description\": \"Experience the future of television with this stunning 8K TV.\",\\n    \"price\": 2999.99\\n}\\n{\\n    \"name\": \"SoundMax Soundbar\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"SoundMax\",\\n    \"model_number\": \"SM-SB50\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.3,\\n    \"features\": [\\n        \"2.1 channel\",\\n        \"300W output\",\\n        \"Wireless subwoofer\",\\n        \"Bluetooth\"\\n    ],\\n    \"description\": \"Upgrade your TV\\'s audio with this sleek and powerful soundbar.\",\\n    \"price\": 199.99\\n}\\n{\\n    \"name\": \"CineView OLED TV\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"CineView\",\\n    \"model_number\": \"CV-OLED55\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.7,\\n    \"features\": [\\n        \"55-inch display\",\\n        \"4K resolution\",\\n        \"HDR\",\\n        \"Smart TV\"\\n    ],\\n    \"description\": \"Experience true blacks and vibrant colors with this OLED TV.\",\\n    \"price\": 1499.99\\n}\\n{\\n    \"name\": \"CineView 4K TV\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"CineView\",\\n    \"model_number\": \"CV-4K55\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.8,\\n    \"features\": [\\n        \"55-inch display\",\\n        \"4K resolution\",\\n        \"HDR\",\\n        \"Smart TV\"\\n    ],\\n    \"description\": \"A stunning 4K TV with vibrant colors and smart features.\",\\n    \"price\": 599.99\\n}\\n',\n",
       " 'chat_history': [HumanMessage(content='What kind of laptops and CineView 4K TV do you have?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"We have a variety of laptops and the CineView 4K TV available. Here's a quick overview:\\n\\n**Laptops:**\\n\\n1. **TechPro Ultrabook**\\n   - 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\\n   - Price: $799.99\\n   - Description: Sleek and lightweight for everyday use.\\n\\n2. **BlueWave Gaming Laptop**\\n   - 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\\n   - Price: $1199.99\\n   - Description: High-performance for an immersive gaming experience.\\n\\n3. **PowerLite Convertible**\\n   - 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\\n   - Price: $699.99\\n   - Description: Versatile convertible with a responsive touchscreen.\\n\\n4. **TechPro Desktop**\\n   - Intel Core i7 processor, 16GB RAM, 1TB HDD, NVIDIA GeForce GTX 1660\\n   - Price: $999.99\\n   - Description: Powerful desktop for work and play.\\n\\n5. **BlueWave Chromebook**\\n   - 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\\n   - Price: $249.99\\n   - Description: Compact and affordable for everyday tasks.\\n\\n**CineView 4K TV:**\\n\\n- **CineView 4K TV**\\n  - 55-inch display, 4K resolution, HDR, Smart TV\\n  - Price: $599.99\\n  - Description: Stunning 4K TV with vibrant colors and smart features.\\n\\nIs there a specific laptop or feature you're interested in, or would you like more details on the CineView 4K TV?\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"We have a variety of laptops and the CineView 4K TV available. Here's a quick overview:\\n\\n**Laptops:**\\n\\n1. **TechPro Ultrabook**\\n   - 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\\n   - Price: $799.99\\n   - Description: Sleek and lightweight for everyday use.\\n\\n2. **BlueWave Gaming Laptop**\\n   - 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\\n   - Price: $1199.99\\n   - Description: High-performance for an immersive gaming experience.\\n\\n3. **PowerLite Convertible**\\n   - 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\\n   - Price: $699.99\\n   - Description: Versatile convertible with a responsive touchscreen.\\n\\n4. **TechPro Desktop**\\n   - Intel Core i7 processor, 16GB RAM, 1TB HDD, NVIDIA GeForce GTX 1660\\n   - Price: $999.99\\n   - Description: Powerful desktop for work and play.\\n\\n5. **BlueWave Chromebook**\\n   - 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\\n   - Price: $249.99\\n   - Description: Compact and affordable for everyday tasks.\\n\\n**CineView 4K TV:**\\n\\n- **CineView 4K TV**\\n  - 55-inch display, 4K resolution, HDR, Smart TV\\n  - Price: $599.99\\n  - Description: Stunning 4K TV with vibrant colors and smart features.\\n\\nIs there a specific laptop or feature you're interested in, or would you like more details on the CineView 4K TV?\"}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_chain.invoke({\"customer_input\":\"What kind of laptops and CineView 4K TV do you have?\", \"product_info\": product_info, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1731341852257,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "VwhO_siT1KXH"
   },
   "outputs": [],
   "source": [
    "class CustomerServiceBot:\n",
    "    def __init__(self):\n",
    "        # Initialize memories\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            input_key=\"customer_input\",\n",
    "            return_messages=True\n",
    "        )\n",
    "\n",
    "        # Product identification chain\n",
    "        self.product_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            output_parser=product_parser,\n",
    "            prompt=product_prompt,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Customer service chain\n",
    "        self.service_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=service_prompt,\n",
    "            output_key=\"response\",\n",
    "            memory=self.memory,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        self.categories, self.products = format_product_database()\n",
    "        self.product_format_instructions = product_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "    def final_chain(self, customer_input):\n",
    "\n",
    "        # Identify products and categories from the customer input\n",
    "        result = self.product_chain.invoke({\"customer_input\": customer_input,\n",
    "                                   \"categories\": self.categories,\n",
    "                                   \"products\": self.products,\n",
    "                                   \"format_instructions\": self.product_format_instructions})\n",
    "\n",
    "        # Generate product information output string\n",
    "        self.product_info = generate_output_string(result[\"text\"].results)\n",
    "\n",
    "        # Process the customer service query\n",
    "        final_result = self.service_chain.invoke({\"customer_input\": customer_input,\n",
    "                                    \"product_info\": self.product_info,\n",
    "                                    \"chat_history\": []})\n",
    "\n",
    "        return final_result\n",
    "\n",
    "    def process_message(self, user_input: str) -> str:\n",
    "        \"\"\"Process a user message and generate a response\"\"\"\n",
    "        try:\n",
    "            final_result = self.final_chain(user_input)\n",
    "            return final_result[\"response\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message: {e}\")\n",
    "            return \"I apologize, but I encountered an error processing your request. Could you please rephrase your question?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113153,
     "status": "ok",
     "timestamp": 1731341979974,
     "user": {
      "displayName": "Tiago",
      "userId": "14603740172974723628"
     },
     "user_tz": 0
    },
    "id": "mYIwLHGM1KXH",
    "outputId": "e53dccee-5e26-4056-8e61-470d115e50aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Bot initialized. Type 'exit' or 'quit' to end the conversation.\n",
      "You: Hello\n",
      "Bot: Hello! How can I assist you with your electronics needs today?\n",
      "You: What kind of laptops do you have?\n",
      "Bot: We have a variety of laptops to suit different needs and budgets. Here are some options:\n",
      "\n",
      "1. **TechPro Ultrabook**\n",
      "   - **Price:** $799.99\n",
      "   - **Features:** 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\n",
      "   - **Description:** A sleek and lightweight ultrabook for everyday use.\n",
      "\n",
      "2. **BlueWave Gaming Laptop**\n",
      "   - **Price:** $1199.99\n",
      "   - **Features:** 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\n",
      "   - **Description:** A high-performance gaming laptop for an immersive experience.\n",
      "\n",
      "3. **PowerLite Convertible**\n",
      "   - **Price:** $699.99\n",
      "   - **Features:** 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\n",
      "   - **Description:** A versatile convertible laptop with a responsive touchscreen.\n",
      "\n",
      "4. **BlueWave Chromebook**\n",
      "   - **Price:** $249.99\n",
      "   - **Features:** 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\n",
      "   - **Description:** A compact and affordable Chromebook for everyday tasks.\n",
      "\n",
      "Is there a specific type of laptop or feature you are looking for?\n",
      "You:  I want to buy a BlueWave Chromebook\n",
      "Bot: Great choice! The BlueWave Chromebook is a compact and affordable option, perfect for everyday tasks. Here are some key details:\n",
      "\n",
      "- **Display:** 11.6-inch\n",
      "- **RAM:** 4GB\n",
      "- **Storage:** 32GB eMMC\n",
      "- **Operating System:** Chrome OS\n",
      "- **Price:** $249.99\n",
      "- **Warranty:** 1 year\n",
      "- **Rating:** 4.1 out of 5\n",
      "\n",
      "Would you like to know about availability, or do you have any other questions about this Chromebook?\n",
      "You: I'm good, you can place my order\n",
      "Bot: I'm glad to hear you're ready to make a purchase! To place your order for the BlueWave Chromebook, I'll need a few details. Could you please confirm if you'd like to pick it up in-store or have it delivered to your address? Additionally, do you have an account with us, or would you like to proceed as a guest?\n",
      "You: exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "bot = CustomerServiceBot()\n",
    "print(\"Customer Service Bot initialized. Type 'exit' or 'quit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        response = bot.process_message(user_input)\n",
    "        print(f\"Bot: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(\"Please try again with a different query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7VlYvEu1KXH",
    "outputId": "74bfd3bd-3c81-46da-d5d0-af1feb07db00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello! How can I assist you with your electronics needs today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What can you tell me about laptops?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='We have a variety of laptops to suit different needs and budgets. Here are a few options:\\n\\n1. **TechPro Ultrabook**:\\n   - **Price**: $799.99\\n   - **Features**: 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\\n   - **Description**: A sleek and lightweight ultrabook for everyday use.\\n   - **Warranty**: 1 year\\n   - **Rating**: 4.5\\n\\n2. **BlueWave Gaming Laptop**:\\n   - **Price**: $1199.99\\n   - **Features**: 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\\n   - **Description**: A high-performance gaming laptop for an immersive experience.\\n   - **Warranty**: 2 years\\n   - **Rating**: 4.7\\n\\n3. **PowerLite Convertible**:\\n   - **Price**: $699.99\\n   - **Features**: 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\\n   - **Description**: A versatile convertible laptop with a responsive touchscreen.\\n   - **Warranty**: 1 year\\n   - **Rating**: 4.3\\n\\n4. **BlueWave Chromebook**:\\n   - **Price**: $249.99\\n   - **Features**: 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\\n   - **Description**: A compact and affordable Chromebook for everyday tasks.\\n   - **Warranty**: 1 year\\n   - **Rating**: 4.1\\n\\nAre you looking for a specific type of laptop, like one for gaming, work, or general use? Let me know if you need more details on any of these options!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNoI8nN11KXI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
