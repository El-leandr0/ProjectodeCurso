{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Class 9: Part 2 - LangChain Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **PromptTemplates**: We will start with PromptTemplates, which are structures that allow more dynamic and reusable prompts for language models. By using placeholders, you will be able to inject custom data into your prompts, making them more adaptable for various applications across different contexts.\n",
    "\n",
    "2. **Output Parsers**: Next, we will discuss Output Parsers, tools that help interpret and process the raw outputs from language models. These parsers can transform responses into structured formats like JSON or extract specific information, making it easier to handle and utilize the output in your applications.\n",
    "\n",
    "3. **Memory**: Memory mechanisms in LangChain will allow models to retain context across interactions. This is crucial for maintaining coherent dialogues, especially when building conversational applications. You will learn how different types of memory can be implemented to store and retrieve past interactions.\n",
    "\n",
    "4. **Chains**: We will explore Chains, which are sequences of calls to language models and other utilities. Chains will enable you to link multiple operations together, allowing more complex interactions and processing workflows while maintaining modularity.\n",
    "\n",
    "5. **Creating a Chatbot**: Finally, we will apply all these concepts to create a simple chatbot. By using prompt templates for questions, output parsers for understanding responses, chains for coordinating the conversation flow, and memory for context retention, you will build a basic yet functional conversational agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "LangChain is an innovative framework designed to streamline the development of applications powered by large language models (LLMs). It offers a set of tools and abstractions that make it easier to build complex, functionality-rich applications by orchestrating interactions with these models. At its core, LangChain provides components such as PromptTemplates, Output Parsers, and Chains, which facilitate the creation of dynamic prompts, structured output processing, and sequences of operations, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_completion(prompt, model='gpt-3.5-turbo', **kwargs):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        **kwargs,# this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "llm = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we want to translate an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Exmo(a) Sr(a), \\\n",
    "Espero que este email o(a) encontre bem. \\\n",
    "Venho por este meio solicitar informações detalhadas sobre os serviços que a vossa empresa oferece. \\\n",
    "Estou interessado(a) em saber mais sobre os vossos produtos e soluções, bem como os preços e condições de pagamento. \\\n",
    "Gostaria também de agendar uma reunião para discutir possíveis parcerias e oportunidades de negócio. \\\n",
    "Por favor, indiquem-me a disponibilidade da vossa equipa para um encontro presencial ou virtual. \\\n",
    "Agradeço desde já a vossa atenção e aguardo ansiosamente pela vossa resposta. \\\n",
    "Com os melhores cumprimentos\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare a prompt that combines the email and the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks\n",
    "into a style that is {style}.\n",
    "text: ```{email}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the LangChain OpenAI Client returns an object of type AIMessage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Dear Sir/Madam,\\n\\nI hope this email finds you well. I am reaching out to request detailed information about the services your company offers. I am interested in learning more about your products and solutions, as well as pricing and payment terms. I would also like to schedule a meeting to discuss potential partnerships and business opportunities. Please let me know the availability of your team for an in-person or virtual meeting. Thank you for your attention and I look forward to your response.\\n\\nBest regards,', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 190, 'total_tokens': 287, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7010db80-5136-4dcc-8c39-0a6d9c9bf179-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sir/Madam,\n",
      "\n",
      "I hope this email finds you well. I am reaching out to request detailed information about the services your company offers. I am interested in learning more about your products and solutions, as well as pricing and payment terms. I would also like to schedule a meeting to discuss potential partnerships and business opportunities. Please let me know the availability of your team for an in-person or virtual meeting. Thank you for your attention and I look forward to your response.\n",
      "\n",
      "Best regards,\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to repeate the process for another language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "It is useful to reuse good and complex prompts and detailed.\n",
    "Prompt Templates are a good abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system and human message templates\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"Translate the text that is delimited by triple backticks into a style that is {style}.\"\"\"\n",
    ")\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: ```{text}```\"\n",
    ")\n",
    "\n",
    "# Combine them into a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_template,\n",
    "    human_message_template,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}.')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the style and lyrics\n",
    "style = \"\"\"English UK very polite and respectful as if you were royalty, if necessary corrects the grammar\"\"\"\n",
    "\n",
    "lyrics = \"\"\"\n",
    "Liguei pra ouvir a tua voz \\\n",
    "Mas diz se não tiveres a sós \\\n",
    "Eu sei que tenho escutas, tenho meo tenho zon e tenho Vodafone \\\n",
    "Amigos coloridos, tenho vários benefícios nunca friend-zone \\\n",
    "Tipo esse burro do teu ex-damo com bué perfis \\\n",
    "'Tava na escola em frente a um quadro \\\n",
    "Da única vez que ele viu giz \\\n",
    "\"\"\"\n",
    "\n",
    "# Format the message with the given style and lyrics\n",
    "lyrics_message = prompt_template.format_messages(style=style, text=lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the text that is delimited by triple backticks into a style that is English UK very polite and respectful as if you were royalty, if necessary corrects the grammar.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"text: ```\\nLiguei pra ouvir a tua voz Mas diz se não tiveres a sós Eu sei que tenho escutas, tenho meo tenho zon e tenho Vodafone Amigos coloridos, tenho vários benefícios nunca friend-zone Tipo esse burro do teu ex-damo com bué perfis 'Tava na escola em frente a um quadro Da única vez que ele viu giz ```\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I beseech thee to lend me thine ear, but do tell me if thou art not alone. I am aware that I am being listened to, for I possess Meo, Zon, and Vodafone. I have friends with benefits, never in the friend-zone. Like that fool of thy former lover with numerous profiles. He was at school in front of a blackboard, the only time he saw chalk.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 140, 'total_tokens': 226, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ac95e408-86b6-47dd-bad0-09f56b6aa308-0')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "response = llm.invoke(lyrics_message)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation\n",
    "Sometimes you want the LLM to output the answer in a given format.\n",
    "Let's start with defining how we would like the LLM output to look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a product review output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of customer review output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of prompt to extract the product information from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system and human message templates\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price, \n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: {text}\"\n",
    ")\n",
    "\n",
    "# Combine them into a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_template,\n",
    "    human_message_template,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gift\": true,\n",
      "    \"delivery_days\": 2,\n",
      "    \"price_value\": [\n",
      "        \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system and human message templates\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: {text}\"\n",
    ")\n",
    "\n",
    "# Combine them into a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_template,\n",
    "    human_message_template,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 1: StructuredOutputParser and ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.output_parsers import ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema,\n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser1 = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions1 = output_parser1.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = prompt_template | llm | output_parser1\n",
    "output1 = chain1.invoke({\"text\": customer_review, \"format_instructions\": format_instructions1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gift': True, 'delivery_days': '2', 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}\n"
     ]
    }
   ],
   "source": [
    "print(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 2: PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class ProductReview(BaseModel):\n",
    "    gift: bool = Field(\n",
    "        description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\"\n",
    "    )\n",
    "    delivery_days: int = Field(\n",
    "        description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\"\n",
    "    )\n",
    "    price_value: List[str] = Field(\n",
    "        description=\"Extract any sentences about the value or price, and output them as a comma-separated Python list.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser2 = PydanticOutputParser(pydantic_object=ProductReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions2 = output_parser2.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = prompt_template | llm | output_parser2\n",
    "output2 = chain2.invoke({\"text\": customer_review, \"format_instructions\": format_instructions2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductReview(gift=True, delivery_days=2, price_value=[\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation\n",
    "When you interact with this LLM they typically don't remember what you say.\n",
    "Which is useful in conversation for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Tiago, nice to meet you! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response1 = llm.invoke(\"Hello my name is Tiago.\")\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I do not have access to personal information such as your name.\n"
     ]
    }
   ],
   "source": [
    "response1 = llm.invoke(\"What is my name?\")\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a conversation chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chat = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the memory\n",
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_result = conversation.invoke(\"Hello my name is Tiago.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello my name is Tiago.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello Tiago! How can I assist you today?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_result['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_result = conversation.invoke(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello my name is Tiago.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello Tiago! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Tiago.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_result['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Tiago.'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_result['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation\n",
    "When you want to be modular and reuse prompts you already have. It also simplifies the flow of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = get_completion(\"\"\"Give me 6 pairs of (product names | reviews) the reviews migth be in different languages,\n",
    "                          but each product shoud only contain one review, each review should contain at least 30 words.\\\n",
    "                          The output should be in json format with two main keys 'products' and 'reviews' \\\n",
    "                           take into account it is suposse to save on a pandas dataframe. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiago\\AppData\\Local\\Temp\\ipykernel_9856\\3897400281.py:2: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(answer)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(answer)\n",
    "df.rename(columns={'products': 'Product', 'reviews': 'Review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone 12 Pro</td>\n",
       "      <td>The iPhone 12 Pro is an amazing phone with a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AirPods Pro</td>\n",
       "      <td>Les AirPods Pro sont incroyables! La qualité d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nintendo Switch</td>\n",
       "      <td>La Nintendo Switch es una consola increíble. L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dyson V11</td>\n",
       "      <td>El Dyson V11 es una aspiradora potente y efici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instant Pot</td>\n",
       "      <td>Instant Pot is a game-changer in the kitchen! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fitbit Versa 3</td>\n",
       "      <td>O Fitbit Versa 3 é um ótimo smartwatch. A tela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Product                                             Review\n",
       "0    iPhone 12 Pro  The iPhone 12 Pro is an amazing phone with a s...\n",
       "1      AirPods Pro  Les AirPods Pro sont incroyables! La qualité d...\n",
       "2  Nintendo Switch  La Nintendo Switch es una consola increíble. L...\n",
       "3        Dyson V11  El Dyson V11 es una aspiradora potente y efici...\n",
       "4      Instant Pot  Instant Pot is a game-changer in the kitchen! ...\n",
       "5   Fitbit Versa 3  O Fitbit Versa 3 é um ótimo smartwatch. A tela..."
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you want to answer customer reviews, and those reviews might be in different languages.\n",
    "\n",
    "And from those reviews you want to extract a summary of the review.\n",
    "\n",
    "Finally you want to answer the review in the same language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the language model\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define the prompt template for translation\n",
    "first_prompt = ChatPromptTemplate.from_messages(\n",
    "    [   \n",
    "        SystemMessagePromptTemplate.from_template(\"Translate the following review to English.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{Review}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain for translating the review to English\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"english_Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for summarization\n",
    "second_prompt = ChatPromptTemplate.from_messages(\n",
    "    [   \n",
    "        SystemMessagePromptTemplate.from_template(\"Summarize the following review in 1 sentence.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{english_Review}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain for summarizing the English review\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template to identify the language of the review\n",
    "third_prompt = ChatPromptTemplate.from_messages(\n",
    "    [   \n",
    "        SystemMessagePromptTemplate.from_template(\"Identify the language of the following review.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{Review}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain for identifying the language of the review\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for a follow-up message\n",
    "fourth_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"Write a follow-up response to the following summary in the specified language.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"Summary: {summary}\\n\\nLanguage: {language}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain for generating a follow-up message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"followup_message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall chain: input = Review, and output = English_Review, summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"english_Review\", \"summary\", \"followup_message\"],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': 'Les AirPods Pro sont incroyables! La qualité du son est incroyable et la réduction du bruit fonctionne très bien. Ils sont confortables à porter et la durée de vie de la batterie est excellente.',\n",
       " 'english_Review': 'The AirPods Pro are amazing! The sound quality is incredible and the noise cancellation works very well. They are comfortable to wear and the battery life is excellent.',\n",
       " 'summary': 'The reviewer is highly impressed with the AirPods Pro, praising their sound quality, noise cancellation, comfort, and battery life.',\n",
       " 'followup_message': \"Merci pour votre commentaire élogieux sur les AirPods Pro ! Nous sommes ravis que vous ayez apprécié la qualité sonore, la suppression du bruit, le confort et l'autonomie de la batterie de ces écouteurs. Vos éloges nous encouragent à continuer à proposer des produits de haute qualité. N'hésitez pas à nous faire part de vos expériences ou besoins supplémentaires à l'avenir.\"}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[1]\n",
    "overall_chain.invoke(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RouterChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we want to have multiple prompts and we want to choose one based on the output of the previous prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{text}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts,\n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{text}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{text}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity.\n",
    "\n",
    "Here is a question:\n",
    "{text}\"\"\"\n",
    "\n",
    "\n",
    "default_template = \"\"\"You are a helpful AI assistant. \\\n",
    "You can answer questions on a wide range of topics. \\\n",
    "If you're not sure about an answer, you can say so.\n",
    "\n",
    "Here is the question:\n",
    "{text}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from those prompts lets create prompt tempates and chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiago\\AppData\\Local\\Temp\\ipykernel_22076\\4125052752.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  destination_chains[name] = LLMChain(llm=llm, prompt=prompt_template)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "templates = [physics_template, math_template, history_template, computerscience_template, default_template]\n",
    "names = [\"Physics\", \"Math\", \"History\", \"Computer Science\", \"Default\"]\n",
    "destination_chains = {}\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: {text}\"\n",
    ")\n",
    "\n",
    "for system_template, name in zip(templates, names):\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        human_message_template,\n",
    "    ])\n",
    "\n",
    "    destination_chains[name] = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Physics, Math, History, Computer Science, Default]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations = list(destination_chains.keys()) \n",
    "destinations_str = \"[\"+\", \".join(destinations)+\"]\"\n",
    "destinations_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Pydantic Class to extract the destination chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Given a raw text input to a language model select the destination that best suits the input.\"\"\"\n",
    "    destination: Literal[\"Physics\", \"Math\", \"History\", \"Computer Science\", \"Default\"] \n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=RouteQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a main chain that will be used in the router chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system and human message templates\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "\n",
    "Available prompts: {destinations_str}\n",
    "\n",
    "If any of the prompts are not suitable for the input, output 'Default'.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\n",
    "    \"text: {text}\"\n",
    ")\n",
    "\n",
    "# Combine them into a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_message_template,\n",
    "    human_message_template,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What is 1+1?\"\n",
    "\n",
    "# Define the chain that will be used to route the input text to the correct destination\n",
    "route_chain = prompt_template | llm | output_parser\n",
    "\n",
    "# Extract the Pydantic object from the output of the route chain\n",
    "route_object = route_chain.invoke({\"text\": text, \"destinations_str\":destinations_str, \"format_instructions\": output_parser.get_format_instructions()})\n",
    "\n",
    "# Extract the destination from the Pydantic object\n",
    "destination = route_object.destination\n",
    "\n",
    "# Use the destination to invoke the correct destination chain\n",
    "answer = destination_chains[destination].invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Database\n",
    "PRODUCT_DATABASE = {\n",
    "    \"Computers and Laptops\": [\n",
    "        \"TechPro Ultrabook\",\n",
    "        \"BlueWave Gaming Laptop\",\n",
    "        \"PowerLite Convertible\",\n",
    "        \"TechPro Desktop\",\n",
    "        \"BlueWave Chromebook\"\n",
    "    ],\n",
    "    \"Smartphones and Accessories\": [\n",
    "        \"SmartX ProPhone\",\n",
    "        \"MobiTech PowerCase\",\n",
    "        \"SmartX MiniPhone\",\n",
    "        \"MobiTech Wireless Charger\",\n",
    "        \"SmartX EarBuds\"\n",
    "    ],\n",
    "    \"Televisions and Home Theater Systems\": [\n",
    "        \"CineView 4K TV\",\n",
    "        \"SoundMax Home Theater\",\n",
    "        \"CineView 8K TV\",\n",
    "        \"SoundMax Soundbar\",\n",
    "        \"CineView OLED TV\"\n",
    "    ],\n",
    "    \"Gaming Consoles and Accessories\": [\n",
    "        \"GameSphere X\",\n",
    "        \"ProGamer Controller\",\n",
    "        \"GameSphere Y\",\n",
    "        \"ProGamer Racing Wheel\",\n",
    "        \"GameSphere VR Headset\"\n",
    "    ],\n",
    "    \"Audio Equipment\": [\n",
    "        \"AudioPhonic Noise-Canceling Headphones\",\n",
    "        \"WaveSound Bluetooth Speaker\",\n",
    "        \"AudioPhonic True Wireless Earbuds\",\n",
    "        \"WaveSound Soundbar\",\n",
    "        \"AudioPhonic Turntable\"\n",
    "    ],\n",
    "    \"Cameras and Camcorders\": [\n",
    "        \"FotoSnap DSLR Camera\",\n",
    "        \"ActionCam 4K\",\n",
    "        \"FotoSnap Mirrorless Camera\",\n",
    "        \"ZoomMaster Camcorder\",\n",
    "        \"FotoSnap Instant Camera\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def format_product_database():\n",
    "    \"\"\"Format the product database for prompt templates\"\"\"\n",
    "    categories = \"\\n\".join(f\"- {category}\" for category in PRODUCT_DATABASE.keys())\n",
    "    products = \"\\n\".join(\n",
    "        f\"{category}:\\n\" + \"\\n\".join(f\"  - {product}\" for product in products)\n",
    "        for category, products in PRODUCT_DATABASE.items()\n",
    "    )\n",
    "    return categories, products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dictionary from the pickle file\n",
    "with open('products_catalog.pkl', 'rb') as handle:\n",
    "  products_catalog = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories, products = format_product_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import json\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic models for structured output\n",
    "class ProductCategory(BaseModel):\n",
    "    category: Optional[str] = Field(None, description=\"The product category\")\n",
    "    products: Optional[List[str]] = Field(None, description=\"List of products mentioned\")\n",
    "\n",
    "class ProductQueryResult(BaseModel):\n",
    "    results: List[ProductCategory]\n",
    "\n",
    "product_parser = PydanticOutputParser(pydantic_object=ProductQueryResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product identification prompt templates\n",
    "PRODUCT_SYSTEM_TEMPLATE = \"\"\"\n",
    "You are a product identification system for an electronics store.\n",
    "Your task is to analyze customer service queries and identify mentioned products and categories.\n",
    "\n",
    "Available categories:\n",
    "{categories}\n",
    "\n",
    "Available products:\n",
    "{products}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Ensure your response follows the exact format specified in the instructions.\n",
    "\"\"\"\n",
    "\n",
    "PRODUCT_HUMAN_TEMPLATE = \"\"\"\n",
    "Customer Query: {customer_input}\n",
    "\"\"\"\n",
    "\n",
    "product_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(PRODUCT_SYSTEM_TEMPLATE),\n",
    "    HumanMessagePromptTemplate.from_template(PRODUCT_HUMAN_TEMPLATE)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product identification chain\n",
    "product_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    output_parser=product_parser,\n",
    "    prompt=product_prompt,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = product_chain.invoke({\"customer_input\":\"What kind of laptops and CineView 4K TV do you have?\", \"categories\": categories, \"products\": products, \"format_instructions\": product_parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer_input': 'What kind of laptops and CineView 4K TV do you have?',\n",
       " 'categories': '- Computers and Laptops\\n- Smartphones and Accessories\\n- Televisions and Home Theater Systems\\n- Gaming Consoles and Accessories\\n- Audio Equipment\\n- Cameras and Camcorders',\n",
       " 'products': 'Computers and Laptops:\\n  - TechPro Ultrabook\\n  - BlueWave Gaming Laptop\\n  - PowerLite Convertible\\n  - TechPro Desktop\\n  - BlueWave Chromebook\\nSmartphones and Accessories:\\n  - SmartX ProPhone\\n  - MobiTech PowerCase\\n  - SmartX MiniPhone\\n  - MobiTech Wireless Charger\\n  - SmartX EarBuds\\nTelevisions and Home Theater Systems:\\n  - CineView 4K TV\\n  - SoundMax Home Theater\\n  - CineView 8K TV\\n  - SoundMax Soundbar\\n  - CineView OLED TV\\nGaming Consoles and Accessories:\\n  - GameSphere X\\n  - ProGamer Controller\\n  - GameSphere Y\\n  - ProGamer Racing Wheel\\n  - GameSphere VR Headset\\nAudio Equipment:\\n  - AudioPhonic Noise-Canceling Headphones\\n  - WaveSound Bluetooth Speaker\\n  - AudioPhonic True Wireless Earbuds\\n  - WaveSound Soundbar\\n  - AudioPhonic Turntable\\nCameras and Camcorders:\\n  - FotoSnap DSLR Camera\\n  - ActionCam 4K\\n  - FotoSnap Mirrorless Camera\\n  - ZoomMaster Camcorder\\n  - FotoSnap Instant Camera',\n",
       " 'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"$defs\": {\"ProductCategory\": {\"properties\": {\"category\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The product category\", \"title\": \"Category\"}, \"products\": {\"anyOf\": [{\"items\": {\"type\": \"string\"}, \"type\": \"array\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"List of products mentioned\", \"title\": \"Products\"}}, \"title\": \"ProductCategory\", \"type\": \"object\"}}, \"properties\": {\"results\": {\"items\": {\"$ref\": \"#/$defs/ProductCategory\"}, \"title\": \"Results\", \"type\": \"array\"}}, \"required\": [\"results\"]}\\n```',\n",
       " 'text': ProductQueryResult(results=[ProductCategory(category='Computers and Laptops', products=None), ProductCategory(category='Televisions and Home Theater Systems', products=['CineView 4K TV'])])}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_by_name(name):\n",
    "    return products_catalog.get(name, None)\n",
    "\n",
    "def get_products_by_category(category):\n",
    "    return [product for product in products_catalog.values() if product[\"category\"] == category]\n",
    "\n",
    "def generate_output_string(data_list):\n",
    "    output_string = \"\"\n",
    "\n",
    "    if data_list is None:\n",
    "        return output_string\n",
    "\n",
    "    for data in data_list:\n",
    "        try:\n",
    "            # Check if the data is a instance of ProductCategory\n",
    "            if isinstance(data, ProductCategory):\n",
    "\n",
    "                # Check if the category is specified\n",
    "                if data.category:\n",
    "                    #print(f\"Category: {data.category}\")\n",
    "                    category_products = get_products_by_category(data.category)\n",
    "                    for product in category_products:\n",
    "                        output_string += json.dumps(product, indent=4) + \"\\n\"\n",
    "                \n",
    "                # Check if the products are specified\n",
    "                if data.products:\n",
    "                    for product_name in data.products:\n",
    "                        #print(f\"Product: {product_name}\")\n",
    "                        product = get_product_by_name(product_name)\n",
    "                        if product:\n",
    "                            output_string += json.dumps(product, indent=4) + \"\\n\"\n",
    "                        else:\n",
    "                            print(f\"Error: Product '{product_name}' not found\")\n",
    "            else:\n",
    "                print(\"Error: Invalid object format\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info = generate_output_string(result[\"text\"].results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer service prompt templates\n",
    "SERVICE_SYSTEM_TEMPLATE = \"\"\"\n",
    "You are a friendly and helpful customer service assistant for a large electronics store.\n",
    "Follow these guidelines:\n",
    "1. Provide concise, helpful responses\n",
    "2. Ask relevant follow-up questions when needed\n",
    "3. Show understanding of specific products mentioned\n",
    "4. Be professional but conversational in tone\n",
    "5. Focus on solving the customer's immediate needs\n",
    "\"\"\"\n",
    "\n",
    "SERVICE_HUMAN_TEMPLATE = \"\"\"\n",
    "Product Information from Query:\n",
    "{product_info}\n",
    "\n",
    "Customer Query: {customer_input}\n",
    "\"\"\"\n",
    "\n",
    "service_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(SERVICE_SYSTEM_TEMPLATE),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    HumanMessagePromptTemplate.from_template(SERVICE_HUMAN_TEMPLATE)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        input_key=\"customer_input\",\n",
    "        return_messages=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product identification chain\n",
    "service_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=service_prompt,\n",
    "    output_key=\"response\",\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer_input': 'What kind of laptops and CineView 4K TV do you have?',\n",
       " 'product_info': '{\\n    \"name\": \"TechPro Ultrabook\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"TechPro\",\\n    \"model_number\": \"TP-UB100\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.5,\\n    \"features\": [\\n        \"13.3-inch display\",\\n        \"8GB RAM\",\\n        \"256GB SSD\",\\n        \"Intel Core i5 processor\"\\n    ],\\n    \"description\": \"A sleek and lightweight ultrabook for everyday use.\",\\n    \"price\": 799.99\\n}\\n{\\n    \"name\": \"BlueWave Gaming Laptop\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"BlueWave\",\\n    \"model_number\": \"BW-GL200\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.7,\\n    \"features\": [\\n        \"15.6-inch display\",\\n        \"16GB RAM\",\\n        \"512GB SSD\",\\n        \"NVIDIA GeForce RTX 3060\"\\n    ],\\n    \"description\": \"A high-performance gaming laptop for an immersive experience.\",\\n    \"price\": 1199.99\\n}\\n{\\n    \"name\": \"PowerLite Convertible\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"PowerLite\",\\n    \"model_number\": \"PL-CV300\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.3,\\n    \"features\": [\\n        \"14-inch touchscreen\",\\n        \"8GB RAM\",\\n        \"256GB SSD\",\\n        \"360-degree hinge\"\\n    ],\\n    \"description\": \"A versatile convertible laptop with a responsive touchscreen.\",\\n    \"price\": 699.99\\n}\\n{\\n    \"name\": \"TechPro Desktop\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"TechPro\",\\n    \"model_number\": \"TP-DT500\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.4,\\n    \"features\": [\\n        \"Intel Core i7 processor\",\\n        \"16GB RAM\",\\n        \"1TB HDD\",\\n        \"NVIDIA GeForce GTX 1660\"\\n    ],\\n    \"description\": \"A powerful desktop computer for work and play.\",\\n    \"price\": 999.99\\n}\\n{\\n    \"name\": \"BlueWave Chromebook\",\\n    \"category\": \"Computers and Laptops\",\\n    \"brand\": \"BlueWave\",\\n    \"model_number\": \"BW-CB100\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.1,\\n    \"features\": [\\n        \"11.6-inch display\",\\n        \"4GB RAM\",\\n        \"32GB eMMC\",\\n        \"Chrome OS\"\\n    ],\\n    \"description\": \"A compact and affordable Chromebook for everyday tasks.\",\\n    \"price\": 249.99\\n}\\n{\\n    \"name\": \"CineView 4K TV\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"CineView\",\\n    \"model_number\": \"CV-4K55\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.8,\\n    \"features\": [\\n        \"55-inch display\",\\n        \"4K resolution\",\\n        \"HDR\",\\n        \"Smart TV\"\\n    ],\\n    \"description\": \"A stunning 4K TV with vibrant colors and smart features.\",\\n    \"price\": 599.99\\n}\\n{\\n    \"name\": \"SoundMax Home Theater\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"SoundMax\",\\n    \"model_number\": \"SM-HT100\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.4,\\n    \"features\": [\\n        \"5.1 channel\",\\n        \"1000W output\",\\n        \"Wireless subwoofer\",\\n        \"Bluetooth\"\\n    ],\\n    \"description\": \"A powerful home theater system for an immersive audio experience.\",\\n    \"price\": 399.99\\n}\\n{\\n    \"name\": \"CineView 8K TV\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"CineView\",\\n    \"model_number\": \"CV-8K65\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.9,\\n    \"features\": [\\n        \"65-inch display\",\\n        \"8K resolution\",\\n        \"HDR\",\\n        \"Smart TV\"\\n    ],\\n    \"description\": \"Experience the future of television with this stunning 8K TV.\",\\n    \"price\": 2999.99\\n}\\n{\\n    \"name\": \"SoundMax Soundbar\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"SoundMax\",\\n    \"model_number\": \"SM-SB50\",\\n    \"warranty\": \"1 year\",\\n    \"rating\": 4.3,\\n    \"features\": [\\n        \"2.1 channel\",\\n        \"300W output\",\\n        \"Wireless subwoofer\",\\n        \"Bluetooth\"\\n    ],\\n    \"description\": \"Upgrade your TV\\'s audio with this sleek and powerful soundbar.\",\\n    \"price\": 199.99\\n}\\n{\\n    \"name\": \"CineView OLED TV\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"CineView\",\\n    \"model_number\": \"CV-OLED55\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.7,\\n    \"features\": [\\n        \"55-inch display\",\\n        \"4K resolution\",\\n        \"HDR\",\\n        \"Smart TV\"\\n    ],\\n    \"description\": \"Experience true blacks and vibrant colors with this OLED TV.\",\\n    \"price\": 1499.99\\n}\\n{\\n    \"name\": \"CineView 4K TV\",\\n    \"category\": \"Televisions and Home Theater Systems\",\\n    \"brand\": \"CineView\",\\n    \"model_number\": \"CV-4K55\",\\n    \"warranty\": \"2 years\",\\n    \"rating\": 4.8,\\n    \"features\": [\\n        \"55-inch display\",\\n        \"4K resolution\",\\n        \"HDR\",\\n        \"Smart TV\"\\n    ],\\n    \"description\": \"A stunning 4K TV with vibrant colors and smart features.\",\\n    \"price\": 599.99\\n}\\n',\n",
       " 'chat_history': [HumanMessage(content='What kind of laptops and CineView 4K TV do you have?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"We have a variety of laptops and the CineView 4K TV available. Here's a quick overview:\\n\\n**Laptops:**\\n\\n1. **TechPro Ultrabook**\\n   - 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\\n   - Price: $799.99\\n   - Sleek and lightweight for everyday use\\n\\n2. **BlueWave Gaming Laptop**\\n   - 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\\n   - Price: $1199.99\\n   - High-performance for gaming\\n\\n3. **PowerLite Convertible**\\n   - 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\\n   - Price: $699.99\\n   - Versatile with a responsive touchscreen\\n\\n4. **TechPro Desktop**\\n   - Intel Core i7 processor, 16GB RAM, 1TB HDD, NVIDIA GeForce GTX 1660\\n   - Price: $999.99\\n   - Powerful for work and play\\n\\n5. **BlueWave Chromebook**\\n   - 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\\n   - Price: $249.99\\n   - Compact and affordable for everyday tasks\\n\\n**CineView 4K TV:**\\n\\n- **CineView 4K TV**\\n  - 55-inch display, 4K resolution, HDR, Smart TV\\n  - Price: $599.99\\n  - Stunning visuals with vibrant colors and smart features\\n\\nIs there a specific laptop or feature you're interested in, or would you like more details on the CineView 4K TV?\", additional_kwargs={}, response_metadata={})],\n",
       " 'response': \"We have a variety of laptops and the CineView 4K TV available. Here's a quick overview:\\n\\n**Laptops:**\\n\\n1. **TechPro Ultrabook**\\n   - 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\\n   - Price: $799.99\\n   - Sleek and lightweight for everyday use\\n\\n2. **BlueWave Gaming Laptop**\\n   - 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\\n   - Price: $1199.99\\n   - High-performance for gaming\\n\\n3. **PowerLite Convertible**\\n   - 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\\n   - Price: $699.99\\n   - Versatile with a responsive touchscreen\\n\\n4. **TechPro Desktop**\\n   - Intel Core i7 processor, 16GB RAM, 1TB HDD, NVIDIA GeForce GTX 1660\\n   - Price: $999.99\\n   - Powerful for work and play\\n\\n5. **BlueWave Chromebook**\\n   - 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\\n   - Price: $249.99\\n   - Compact and affordable for everyday tasks\\n\\n**CineView 4K TV:**\\n\\n- **CineView 4K TV**\\n  - 55-inch display, 4K resolution, HDR, Smart TV\\n  - Price: $599.99\\n  - Stunning visuals with vibrant colors and smart features\\n\\nIs there a specific laptop or feature you're interested in, or would you like more details on the CineView 4K TV?\"}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_chain.invoke({\"customer_input\":\"What kind of laptops and CineView 4K TV do you have?\", \"product_info\": product_info, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerServiceBot:\n",
    "    def __init__(self):\n",
    "        # Initialize memories\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            input_key=\"customer_input\",\n",
    "            return_messages=True\n",
    "        )\n",
    "        \n",
    "        # Product identification chain\n",
    "        self.product_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            output_parser=product_parser,\n",
    "            prompt=product_prompt,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Customer service chain\n",
    "        self.service_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=service_prompt,\n",
    "            output_key=\"response\",\n",
    "            memory=self.memory,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        self.categories, self.products = format_product_database()\n",
    "        self.product_format_instructions = product_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "    def final_chain(self, customer_input):\n",
    "\n",
    "        # Identify products and categories from the customer input\n",
    "        result = self.product_chain.invoke({\"customer_input\": customer_input, \n",
    "                                   \"categories\": self.categories, \n",
    "                                   \"products\": self.products, \n",
    "                                   \"format_instructions\": self.product_format_instructions})\n",
    "\n",
    "        # Generate product information output string\n",
    "        self.product_info = generate_output_string(result[\"text\"].results)\n",
    "\n",
    "        # Process the customer service query\n",
    "        final_result = self.service_chain.invoke({\"customer_input\": customer_input,\n",
    "                                    \"product_info\": self.product_info,\n",
    "                                    \"chat_history\": []})\n",
    "                                   \n",
    "        return final_result\n",
    "    \n",
    "    def process_message(self, user_input: str) -> str:\n",
    "        \"\"\"Process a user message and generate a response\"\"\"\n",
    "        try:\n",
    "            final_result = self.final_chain(user_input)\n",
    "            return final_result[\"response\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message: {e}\")\n",
    "            return \"I apologize, but I encountered an error processing your request. Could you please rephrase your question?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Service Bot initialized. Type 'exit' or 'quit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I assist you with your electronics needs today?\n",
      "Bot: We have a variety of laptops to suit different needs and budgets. Here are a few options:\n",
      "\n",
      "1. **TechPro Ultrabook**:\n",
      "   - **Price**: $799.99\n",
      "   - **Features**: 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\n",
      "   - **Description**: A sleek and lightweight ultrabook for everyday use.\n",
      "   - **Warranty**: 1 year\n",
      "   - **Rating**: 4.5\n",
      "\n",
      "2. **BlueWave Gaming Laptop**:\n",
      "   - **Price**: $1199.99\n",
      "   - **Features**: 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\n",
      "   - **Description**: A high-performance gaming laptop for an immersive experience.\n",
      "   - **Warranty**: 2 years\n",
      "   - **Rating**: 4.7\n",
      "\n",
      "3. **PowerLite Convertible**:\n",
      "   - **Price**: $699.99\n",
      "   - **Features**: 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\n",
      "   - **Description**: A versatile convertible laptop with a responsive touchscreen.\n",
      "   - **Warranty**: 1 year\n",
      "   - **Rating**: 4.3\n",
      "\n",
      "4. **BlueWave Chromebook**:\n",
      "   - **Price**: $249.99\n",
      "   - **Features**: 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\n",
      "   - **Description**: A compact and affordable Chromebook for everyday tasks.\n",
      "   - **Warranty**: 1 year\n",
      "   - **Rating**: 4.1\n",
      "\n",
      "Are you looking for a specific type of laptop, like one for gaming, work, or general use? Let me know if you need more details on any of these options!\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "bot = CustomerServiceBot()\n",
    "print(\"Customer Service Bot initialized. Type 'exit' or 'quit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    \n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "        response = bot.process_message(user_input)\n",
    "        print(f\"Bot: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(\"Please try again with a different query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello! How can I assist you with your electronics needs today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What can you tell me about laptops?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='We have a variety of laptops to suit different needs and budgets. Here are a few options:\\n\\n1. **TechPro Ultrabook**:\\n   - **Price**: $799.99\\n   - **Features**: 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\\n   - **Description**: A sleek and lightweight ultrabook for everyday use.\\n   - **Warranty**: 1 year\\n   - **Rating**: 4.5\\n\\n2. **BlueWave Gaming Laptop**:\\n   - **Price**: $1199.99\\n   - **Features**: 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\\n   - **Description**: A high-performance gaming laptop for an immersive experience.\\n   - **Warranty**: 2 years\\n   - **Rating**: 4.7\\n\\n3. **PowerLite Convertible**:\\n   - **Price**: $699.99\\n   - **Features**: 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\\n   - **Description**: A versatile convertible laptop with a responsive touchscreen.\\n   - **Warranty**: 1 year\\n   - **Rating**: 4.3\\n\\n4. **BlueWave Chromebook**:\\n   - **Price**: $249.99\\n   - **Features**: 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\\n   - **Description**: A compact and affordable Chromebook for everyday tasks.\\n   - **Warranty**: 1 year\\n   - **Rating**: 4.1\\n\\nAre you looking for a specific type of laptop, like one for gaming, work, or general use? Let me know if you need more details on any of these options!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
